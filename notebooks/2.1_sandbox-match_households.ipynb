{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding activity chains to synthetic populations \n",
    "\n",
    "The purpose of this script is to test different approaches to matching households in the synthetic population to a household from the [National Travel Survey (NTS)](https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=5340). \n",
    "\n",
    "### Methods\n",
    "\n",
    "1. categorical matching: joining on relevant socio-demographic variables\n",
    "2. statistical matching, as described in [An unconstrained statistical matching algorithm for combining individual and household level geo-specific census and survey data](https://doi.org/10.1016/j.compenvurbsys.2016.11.003). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from acbm.preprocessing import (\n",
    "    count_per_group,\n",
    "    match_coverage_col,\n",
    "    nts_filter_by_year,\n",
    "    num_adult_child_hh,\n",
    "    transform_by_group,\n",
    "    truncate_values,\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load in the datasets  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful variables\n",
    "region = \"west-yorkshire\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the spc data (parquet format)\n",
    "spc = pd.read_parquet('../data/external/spc_output/' + region + '_people_hh.parquet')\n",
    "spc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns\n",
    "spc = spc[['id', 'household', 'pid_hs',\n",
    "       'msoa11cd', 'oa11cd', 'members', 'sic1d2007', 'sic2d2007',\n",
    "       'pwkstat', 'salary_yearly', 'salary_hourly', 'hid',\n",
    "       'accommodation_type', 'communal_type', 'num_rooms', 'central_heat',\n",
    "       'tenure', 'num_cars', 'sex', 'age_years', 'ethnicity', 'nssec8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary reduction of the dataset for quick analysis\n",
    "spc = spc.head(50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NTS\n",
    "\n",
    "The NTS is split up into multiple tables. We will load in the following tables:\n",
    "- individuals\n",
    "- households\n",
    "- trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_psu = \"../data/external/nts/UKDA-5340-tab/tab/psu_eul_2002-2022.tab\"\n",
    "psu = pd.read_csv(path_psu, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_individuals = \"../data/external/nts/UKDA-5340-tab/tab/individual_eul_2002-2022.tab\"\n",
    "nts_individuals = pd.read_csv(path_individuals,\n",
    "                              sep=\"\\t\",\n",
    "                              usecols = ['IndividualID',\n",
    "                                         'HouseholdID',\n",
    "                                          'PSUID',\n",
    "                                          'Age_B01ID',\n",
    "                                          'Age_B04ID',\n",
    "                                          'Sex_B01ID',\n",
    "                                          'OfPenAge_B01ID',\n",
    "                                          'HRPRelation_B01ID',\n",
    "                                          'EdAttn1_B01ID',\n",
    "                                          'EdAttn2_B01ID',\n",
    "                                          'EdAttn3_B01ID',\n",
    "                                          'OwnCycle_B01ID', # Owns a cycle\n",
    "                                          'DrivLic_B02ID', # type of driving license\n",
    "                                          'CarAccess_B01ID',\n",
    "                                          'IndIncome2002_B02ID',\n",
    "                                          'IndWkGOR_B02ID', # Region of usual place of work\n",
    "                                          'EcoStat_B02ID', # Working status of individual\n",
    "                                          'EcoStat_B03ID',\n",
    "                                          'NSSec_B03ID', # NSSEC high level breakdown\n",
    "                                          'SC_B01ID', # Social class of individual\n",
    "                                          'Stat_B01ID', # employee or self-employed\n",
    "                                          'WkMode_B01ID', # Usual means of travel to work\n",
    "                                          'WkHome_B01ID', # Work from home\n",
    "                                          'PossHom_B01ID', # Is it possible to work from home?\n",
    "                                          'OftHome_B01ID', # How often work from home\n",
    "                                          'TravSh_B01ID', # Usual mode from main food shopping trip\n",
    "                                          'SchDly_B01ID', # Daily school journey?\n",
    "                                          'SchTrav_B01ID', # Usual mode of travel to school\n",
    "                                          'SchAcc_B01ID', # IS school trip accompanied by an adult?\n",
    "                                          'FdShp_B01ID', # How do you usually carry ot main food shop (go to shop, online etc)\n",
    "                                          ]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_households = \"../data/external/nts/UKDA-5340-tab/tab/household_eul_2002-2022.tab\"\n",
    "nts_households = pd.read_csv(path_households,\n",
    "                             sep=\"\\t\",\n",
    "                             usecols = ['HouseholdID',\n",
    "                                        'PSUID',\n",
    "                                        'HHIncome2002_B02ID',\n",
    "                                        'AddressType_B01ID', # type of house\n",
    "                                        'Ten1_B02ID', # type of tenure\n",
    "                                        'HHoldNumAdults', # total no. of adults in household\n",
    "                                        'HHoldNumChildren', # total no. of children in household\n",
    "                                        'HHoldNumPeople', # total no. of people in household\n",
    "                                        'NumLicHolders', # total no. of driving license holders in household\n",
    "                                        'HHoldEmploy_B01ID', # number of employed in household\n",
    "                                        'NumBike', # no. of bikes\n",
    "                                        'NumCar', # no. of cars\n",
    "                                        'NumVanLorry', # no. of vans or lorries\n",
    "                                        'NumMCycle', # no. of motorcycles\n",
    "                                        'WalkBus_B01ID', # walk time from house to nearest bus stop\n",
    "                                        'Getbus_B01ID', # frequency of bus service\n",
    "                                        'WalkRail_B01ID', # walk time from house to nearest rail station\n",
    "                                        'JTimeHosp_B01ID', # journey time to nearest hospital\n",
    "                                        'DVShop_B01ID', # person no. for main food shooper in hh\n",
    "                                        'Settlement2011EW_B03ID', # ONS Urban/Rural: 2 categories\n",
    "                                        'Settlement2011EW_B04ID', # ONS Urban/Rural: 3 categories\n",
    "                                        'HHoldOAClass2011_B03ID', # Census 2011 OA Classification\n",
    "                                        'HRPWorkStat_B02ID', # HH ref person working status\n",
    "                                        'HRPSEGWorkStat_B01ID', #  HH ref person socio economic group for active workers\n",
    "                                        'W0', # Unweighted interview sample\n",
    "                                        'W1', # Unweighted diary sample\n",
    "                                        'W2', # Weighted diary sample\n",
    "                                        'W3', # Weighted interview sample\n",
    "                                        ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_trips = \"../data/external/nts/UKDA-5340-tab/tab/trip_eul_2002-2022.tab\"\n",
    "nts_trips = pd.read_csv(path_trips,\n",
    "                        sep=\"\\t\",\n",
    "                        usecols = ['TripID',\n",
    "                                   'DayID',\n",
    "                                   'IndividualID',\n",
    "                                   'HouseholdID',\n",
    "                                   'PSUID',\n",
    "                                   'PersNo',\n",
    "                                   'TravDay',\n",
    "                                   'JourSeq',\n",
    "                                   'ShortWalkTrip_B01ID',\n",
    "                                   'NumStages',\n",
    "                                   'MainMode_B03ID',\n",
    "                                   'MainMode_B04ID',\n",
    "                                   'TripPurpFrom_B01ID',\n",
    "                                   'TripPurpTo_B01ID',\n",
    "                                   'TripPurpose_B04ID',\n",
    "                                   'TripStart',\n",
    "                                   'TripEnd',\n",
    "                                   'TripTotalTime',\n",
    "                                   'TripTravTime',\n",
    "                                   'TripDisIncSW',\n",
    "                                   'TripDisExSW',\n",
    "                                   'TripOrigGOR_B02ID',\n",
    "                                   'TripDestGOR_B02ID',\n",
    "                                   'W5',\n",
    "                                   'W5xHH'\n",
    "                        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter by year\n",
    "\n",
    "We will filter the NTS data to only include data from specific years. We can choose only 1 year, or multiple years to increase our sample size and the likelihood of a match with the spc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2019, 2021, 2022]\n",
    "\n",
    "nts_individuals = nts_filter_by_year(nts_individuals, psu, years)\n",
    "nts_households = nts_filter_by_year(nts_households, psu, years)\n",
    "nts_trips = nts_filter_by_year(nts_trips, psu, years)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter by geography \n",
    "\n",
    "I will not do this for categorical matching, as it reduces the sample significantly, and leads to more spc households not being matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regions = ['Yorkshire and the Humber', 'North West']\n",
    "\n",
    "# nts_individuals = nts_filter_by_region(nts_individuals, psu, regions)\n",
    "# nts_households = nts_filter_by_region(nts_households, psu, regions)\n",
    "# nts_trips = nts_filter_by_region(nts_trips, psu, regions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionaries of key value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "guide to the dictionaries:\n",
    "\n",
    "_nts_hh: from NTS households table\n",
    "_nts_ind: from NTS individuals table\n",
    "_spc: from SPC\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# ---------- NTS\n",
    "\n",
    "# Create a dictionary for the HHIncome2002_B02ID column\n",
    "income_dict_nts_hh = {\n",
    "     '1': '0-25k',\n",
    "     '2': '25k-50k',\n",
    "     '3': '50k+',\n",
    "    '-8': 'NA',\n",
    "    # should be -10, but\n",
    "    # it could be a typo in household_eul_2002-2022_ukda_data_dictionary\n",
    "    '-1': 'DEAD'\n",
    "}\n",
    "\n",
    "# Create a dictionary for the HHoldEmploy_B01ID column\n",
    "# (PT: Part time, FT: Full time)\n",
    "employment_dict_nts_hh = {\n",
    "    '1': 'None',\n",
    "    '2': '0 FT, 1 PT',\n",
    "    '3': '1 FT, 0 PT',\n",
    "    '4': '0 FT, 2 PT',\n",
    "    '5': '1 FT, 1 PT',\n",
    "    '6': '2 FT, 0 PT',\n",
    "    '7': '1 FT, 2+ PT',\n",
    "    '8': '2 FT, 1+ PT',\n",
    "    '9': '0 FT, 3+ PT',\n",
    "    '10': '3+ FT, 0 PT',\n",
    "    '11': '3+ FT, 1+ PT',\n",
    "    '-8': 'NA',\n",
    "    '-10': 'DEAD'\n",
    "}\n",
    "\n",
    "# Create a dictionary for the Ten1_B02ID column\n",
    "tenure_dict_nts_hh = {\n",
    "    '1': 'Owns / buying',\n",
    "    '2': 'Rents',\n",
    "    '3': 'Other (including rent free)',\n",
    "    '-8': 'NA',\n",
    "    '-9': 'DNA',\n",
    "    '-10': 'DEAD'\n",
    "}\n",
    "\n",
    "\n",
    "# ---------- SPC\n",
    "\n",
    "\n",
    "# create a dictionary for the pwkstat column\n",
    "employment_dict_spc = {\n",
    "    '0': 'Not applicable (age < 16)',\n",
    "    '1': 'Employee FT',\n",
    "    '2': 'Employee PT',\n",
    "    '3': 'Employee unspecified',\n",
    "    '4': 'Self-employed',\n",
    "    '5': 'Unemployed',\n",
    "    '6': 'Retired',\n",
    "    '7': 'Homemaker/Maternal leave',\n",
    "    '8': 'Student',\n",
    "    '9': 'Long term sickness/disability',\n",
    "    '10': 'Other'\n",
    "}\n",
    "\n",
    "\n",
    "# Create a dictionary for the tenure column\n",
    "tenure_dict_spc = {\n",
    "    '1': 'Owned: Owned outright',\n",
    "    '2': 'Owned: Owned with a mortgage or loan or shared ownership',\n",
    "    '3': 'Rented or living rent free: Total',\n",
    "    '4': 'Rented: Social rented',\n",
    "    '5': 'Rented: Private rented or living rent free',\n",
    "    '-8': 'NA',\n",
    "    '-9': 'DNA',\n",
    "    '-10': 'DEAD'\n",
    "}\n",
    "\n",
    "\n",
    "# Combine the dictionaries into a dictionary of dictionaries\n",
    "\n",
    "dict_nts = {\n",
    "    'HHIncome2002_B02ID': income_dict_nts_hh,\n",
    "    'HHoldEmploy_B01ID': employment_dict_nts_hh,\n",
    "    'Ten1_B02ID': tenure_dict_nts_hh\n",
    "}\n",
    "\n",
    "dict_spc = {\n",
    "    'pwkstat': employment_dict_spc,\n",
    "    'tenure': tenure_dict_spc\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Decide on matching variables  \n",
    "\n",
    "We need to identify the socio-demographic characteristics that we will match on. The schema for the synthetic population can be found [here](https://github.com/alan-turing-institute/uatk-spc/blob/main/synthpop.proto). \n",
    "\n",
    "Matching between the SPC and the NTS will happen in two steps: \n",
    "\n",
    "1. Match at the household level\n",
    "2. Match individuals within the household\n",
    "\n",
    "### Household level matching \n",
    "\n",
    "| Variable           | Name (NTS)           | Name (SPC)      | Transformation (NTS) | Transformation (SPC) |\n",
    "| ------------------ | -------------------- | --------------- | -------------------- | -------------------- |\n",
    "| Household income   | `HHIncome2002_BO2ID` | `salary_yearly` | NA                   | Group by household ID and sum |\n",
    "| Number of adults   | `HHoldNumAdults`        | `age_years`     | NA                   | Group by household ID and count |\n",
    "| Number of children | `HHoldNumChildren`      | `age_years`     | NA                   | Group by household ID and count |\n",
    "| Employment status  | `HHoldEmploy_B01ID`  | `pwkstat`       | NA                   | a) match to NTS categories. b) group by household ID |\n",
    "| Car ownership      | `NumCar`             | `num_cars`      | SPC is capped at 2. We change all entries > 2 to 2 | NA  |\n",
    "\n",
    "Other columns to match in the future\n",
    "| Variable           | Name (NTS)           | Name (SPC)      | Transformation (NTS) | Transformation (SPC) |\n",
    "| ------------------ | -------------------- | --------------- | -------------------- | -------------------- |\n",
    "| Type of tenancy    | `Ten1_B02ID`         | `tenure`        | ?? | ?? |\n",
    "|  Urban-Rural classification of residence | `Settlement2011EW_B04ID`         | NA     | NA            | Spatial join between [layer](https://www.gov.uk/government/collections/rural-urban-classification) and SPC  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Edit SPC columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Household Income\n",
    "\n",
    "Edit the spc so that we have household income as well as individual income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add household income column for SPC\n",
    "spc_edited = transform_by_group(data = spc,\n",
    "                                group_col = 'household',\n",
    "                                transform_col = 'salary_yearly',\n",
    "                                new_col = 'salary_yearly_hh',\n",
    "                                transformation_type = 'sum')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check number of individuals and households with reported salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram for individuals and households (include NAs as 0)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "ax[0].hist(spc_edited['salary_yearly'].fillna(0), bins=30)\n",
    "ax[0].set_title('Salary yearly (Individuals)')\n",
    "ax[0].set_xlabel('Salary yearly')\n",
    "ax[0].set_ylabel('Frequency')\n",
    "ax[1].hist(spc_edited['salary_yearly_hh'].fillna(0), bins=30)\n",
    "ax[1].set_title('Salary yearly (Households)')\n",
    "ax[1].set_xlabel('Salary yearly')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# statistics\n",
    "\n",
    "# print the total number of rows in the spc. Add a message \"Values =\"\n",
    "print(\"Individuals in SPC =\", spc_edited.shape[0])\n",
    "# number of individuals without reported income\n",
    "print(\"Individuals without reported income =\", spc_edited['salary_yearly'].isna().sum())\n",
    "# % of individuals with reported income (salary_yearly not equal NA)\n",
    "print(\"% of individuals with reported income =\", round((spc_edited['salary_yearly'].count() / spc_edited.shape[0]) * 100, 1))\n",
    "print(\"Individuals with reported income: 0 =\", spc_edited[spc_edited['salary_yearly'] == 0].shape[0])\n",
    "\n",
    "\n",
    "# print the total number of households\n",
    "print(\"Households in SPC =\", spc_edited['household'].nunique())\n",
    "# number of households without reported income (salary yearly_hh = 0)\n",
    "print(\"Households without reported income =\", spc_edited[spc_edited['salary_yearly_hh'] == 0].shape[0])\n",
    "# # % of households with reported income (salary_yearly not equal NA)\n",
    "print(\"% of households with reported income =\", round((spc_edited[spc_edited['salary_yearly_hh'] == 0].shape[0] / spc_edited['household'].nunique()) * 100, 1))\n",
    "print(\"Households with reported income: 0 =\", spc_edited[spc_edited['salary_yearly_hh'] == 0].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Recode column so that it matches the reported NTS values (Use income_dict_nts_hh dictionary for reference)\n",
    "\n",
    "# Define the bins (first )\n",
    "bins = [0, 24999, 49999, np.inf]\n",
    "# Define the labels for the bins\n",
    "labels = [1, 2, 3]\n",
    "\n",
    "spc_edited = spc_edited.copy()\n",
    "\n",
    "spc_edited['salary_yearly_hh_cat'] = (pd.cut(spc_edited['salary_yearly_hh'], bins=bins, labels=labels, include_lowest=True)\n",
    "                                       .astype('str')\n",
    "                                       .astype('float'))\n",
    "\n",
    "\n",
    "# replace NA values with -8 (to be consistent with NTS)\n",
    "spc_edited['salary_yearly_hh_cat'] = spc_edited['salary_yearly_hh_cat'].fillna(-8)\n",
    "\n",
    "# Convert the column to int\n",
    "spc_edited['salary_yearly_hh_cat'] = spc_edited['salary_yearly_hh_cat'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare household income from the SPC and the NTS, we find that the SPC has many more households with no reported income (-8). This will create an issue when matching using household income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot showing spc_edited.salary_yearly_hh_cat and nts_households.HHIncome2002_B02ID side by side\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "ax[0].bar(spc_edited['salary_yearly_hh_cat'].value_counts().index, spc_edited['salary_yearly_hh_cat'].value_counts().values)\n",
    "ax[0].set_title('SPC')\n",
    "ax[0].set_xlabel('Income Bracket - Household level')\n",
    "ax[0].set_ylabel('No of Households')\n",
    "ax[1].bar(nts_households['HHIncome2002_B02ID'].value_counts().index, nts_households['HHIncome2002_B02ID'].value_counts().values)\n",
    "ax[1].set_title('NTS')\n",
    "ax[1].set_xlabel('Income Bracket - Household level')\n",
    "plt.show()\n",
    "\n",
    "# same as above but (%)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "ax[0].bar(spc_edited['salary_yearly_hh_cat'].value_counts(normalize=True).index, spc_edited['salary_yearly_hh_cat'].value_counts(normalize=True).values)\n",
    "ax[0].set_title('SPC')\n",
    "ax[0].set_xlabel('Income Bracket - Household level')\n",
    "ax[0].set_ylabel('Fraction of Households')\n",
    "ax[1].bar(nts_households['HHIncome2002_B02ID'].value_counts(normalize=True).index, nts_households['HHIncome2002_B02ID'].value_counts(normalize=True).values)\n",
    "ax[1].set_title('NTS')\n",
    "ax[1].set_xlabel('Income Bracket - Household level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the % of households in each income bracket for the nts\n",
    "nts_households['HHIncome2002_B02ID'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Household Composition (No. of Adults / Children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of adults and children in the household\n",
    "\n",
    "spc_edited = num_adult_child_hh(data = spc_edited,\n",
    "                                group_col = 'household',\n",
    "                                age_col = 'age_years')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Employment Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employment status\n",
    "\n",
    "# check the colums values from our dictionary\n",
    "dict_spc['pwkstat'], dict_nts['HHoldEmploy_B01ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NTS only reports the number of Full time and Part time employees for each household. For the SPC we also need to get the number of full time and part time workers for each household.\n",
    "\n",
    "Step 1: Create a column for Full time and a column for Part time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will only use '1' and '2' for the employment status\n",
    "\n",
    "counts_df = count_per_group(df = spc_edited,\n",
    "                            group_col = 'household',\n",
    "                            count_col = 'pwkstat',\n",
    "                            values=[1, 2],\n",
    "                            value_names=['pwkstat_FT_hh','pwkstat_PT_hh'])\n",
    "\n",
    "counts_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a column that matches the NTS categories (m FT, n PT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to match the SPC values to the NTS\n",
    "dict_nts['HHoldEmploy_B01ID']\n",
    "'''\n",
    "{\n",
    "    '1': 'None',\n",
    "    '2': '0 FT, 1 PT',\n",
    "    '3': '1 FT, 0 PT',\n",
    "    '4': '0 FT, 2 PT',\n",
    "    '5': '1 FT, 1 PT',\n",
    "    '6': '2 FT, 0 PT',\n",
    "    '7': '1 FT, 2+ PT',\n",
    "    '8': '2 FT, 1+ PT',\n",
    "    '9': '0 FT, 3+ PT',\n",
    "    '10': '3+ FT, 0 PT',\n",
    "    '11': '3+ FT, 1+ PT',\n",
    "    '-8': 'NA',\n",
    "    '-10': 'DEAD'}\n",
    " '''\n",
    "\n",
    "# 1) Match each row to the NTS\n",
    "\n",
    "# Define the conditions and outputs.\n",
    "# We are using the keys in dict_nts['HHoldEmploy_B01ID'] as reference\n",
    "conditions = [\n",
    "    (counts_df['pwkstat_FT_hh'] == 0) & (counts_df['pwkstat_PT_hh'] == 0),\n",
    "    (counts_df['pwkstat_FT_hh'] == 0) & (counts_df['pwkstat_PT_hh'] == 1),\n",
    "    (counts_df['pwkstat_FT_hh'] == 1) & (counts_df['pwkstat_PT_hh'] == 0),\n",
    "    (counts_df['pwkstat_FT_hh'] == 0) & (counts_df['pwkstat_PT_hh'] == 2),\n",
    "    (counts_df['pwkstat_FT_hh'] == 1) & (counts_df['pwkstat_PT_hh'] == 1),\n",
    "    (counts_df['pwkstat_FT_hh'] == 2) & (counts_df['pwkstat_PT_hh'] == 0),\n",
    "    (counts_df['pwkstat_FT_hh'] == 1) & (counts_df['pwkstat_PT_hh'] >= 2),\n",
    "    (counts_df['pwkstat_FT_hh'] == 2) & (counts_df['pwkstat_PT_hh'] >= 1),\n",
    "    (counts_df['pwkstat_FT_hh'] == 0) & (counts_df['pwkstat_PT_hh'] >= 3),\n",
    "    (counts_df['pwkstat_FT_hh'] >= 3) & (counts_df['pwkstat_PT_hh'] == 0),\n",
    "    (counts_df['pwkstat_FT_hh'] >= 3) & (counts_df['pwkstat_PT_hh'] >= 1)\n",
    "]\n",
    "\n",
    "# Define the corresponding outputs based on dict_nts['HHoldEmploy_B01ID]\n",
    "outputs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "\n",
    "# Create a new column using np.select\n",
    "counts_df['pwkstat_NTS_match'] = np.select(conditions,\n",
    "                                           outputs,\n",
    "                                           default= -8)\n",
    "\n",
    "\n",
    "\n",
    "# 2) merge back onto the spc\n",
    "spc_edited = spc_edited.merge(counts_df, left_on='household', right_index=True)\n",
    "\n",
    "# check the output\n",
    "spc_edited[['household', 'pwkstat', 'pwkstat_FT_hh', 'pwkstat_PT_hh', 'pwkstat_NTS_match']].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot of counts_df['pwkstat_NTS_match'] and nts_households['HHoldEmploy_B01ID']\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].bar(counts_df['pwkstat_NTS_match'].value_counts().index, counts_df['pwkstat_NTS_match'].value_counts().values)\n",
    "ax[0].set_title('SPC')\n",
    "ax[0].set_xlabel('Employment status - Household level')\n",
    "ax[0].set_ylabel('Frequency')\n",
    "ax[1].bar(nts_households['HHoldEmploy_B01ID'].value_counts().index, nts_households['HHoldEmploy_B01ID'].value_counts().values)\n",
    "ax[1].set_title('NTS')\n",
    "ax[1].set_xlabel('Employment status - Household level')\n",
    "plt.show()\n",
    "\n",
    "# same as above but percentages\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].bar(counts_df['pwkstat_NTS_match'].value_counts().index, counts_df['pwkstat_NTS_match'].value_counts(normalize=True).values)\n",
    "ax[0].set_title('SPC')\n",
    "ax[0].set_xlabel('Employment status - Household level')\n",
    "ax[0].set_ylabel('Frequency (normalized)')\n",
    "ax[1].bar(nts_households['HHoldEmploy_B01ID'].value_counts().index, nts_households['HHoldEmploy_B01ID'].value_counts(normalize=True).values)\n",
    "ax[1].set_title('NTS')\n",
    "ax[1].set_xlabel('Employment status - Household level')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Urban Rural Classification\n",
    "\n",
    "We use the 2011 rural urban classification to match the SPC to the NTS. The NTS has 2 columns that we can use to match to the SPC: `Settlement2011EW_B03ID` and `Settlement2011EW_B04ID`. The `Settlement2011EW_B03ID` column is more general (urban / rural only), while the `Settlement2011EW_B04ID` column is more specific. We stick to the more general column for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the rural urban classification data\n",
    "rural_urban = pd.read_csv('../data/external/census_2011_rural_urban.csv', sep=',')\n",
    "\n",
    "# merge the rural_urban data with the spc\n",
    "spc_edited = spc_edited.merge(rural_urban[['OA11CD', 'RUC11', 'RUC11CD']], left_on='oa11cd', right_on='OA11CD')\n",
    "spc_edited.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary from the NTS `Settlement2011EW_B03ID` column\n",
    "Settlement2011EW_B03ID_nts_hh = {\n",
    "    '1': 'Urban',\n",
    "    '2': 'Rural',\n",
    "    '3': 'Scotland',\n",
    "    '-8': 'NA',\n",
    "    '-10': 'DEAD'\n",
    "}\n",
    "\n",
    "Settlement2011EW_B04ID_nts_hh = {\n",
    "    '1': 'Urban Conurbation',\n",
    "    '2': 'Urban City and Town',\n",
    "    '3': 'Rural Town and Fringe',\n",
    "    '4': 'Rural Village, Hamlet and Isolated Dwellings',\n",
    "    '5': 'Scotland',\n",
    "    '-8': 'NA',\n",
    "    '-10': 'DEAD'\n",
    "}\n",
    "\n",
    "\n",
    "census_2011_to_nts_B03ID = {\n",
    "    'Urban major conurbation': 'Urban',\n",
    "    'Urban minor conurbation': 'Urban',\n",
    "    'Urban city and town': 'Urban',\n",
    "    'Urban city and town in a sparse setting': 'Urban',\n",
    "    'Rural town and fringe': 'Rural',\n",
    "    'Rural town and fringe in a sparse setting': 'Rural',\n",
    "    'Rural village': 'Rural',\n",
    "    'Rural village in a sparse setting': 'Rural',\n",
    "    'Rural hamlets and isolated dwellings': 'Rural',\n",
    "    'Rural hamlets and isolated dwellings in a sparse setting': 'Rural'\n",
    "}\n",
    "\n",
    "census_2011_to_nts_B04ID = {\n",
    "    'Urban major conurbation': 'Urban Conurbation',\n",
    "    'Urban minor conurbation': 'Urban Conurbation',\n",
    "    'Urban city and town': 'Urban City and Town',\n",
    "    'Urban city and town in a sparse setting': 'Urban City and Town',\n",
    "    'Rural town and fringe': 'Rural Town and Fringe',\n",
    "    'Rural town and fringe in a sparse setting': 'Rural Town and Fringe',\n",
    "    'Rural village': 'Rural Village, Hamlet and Isolated Dwellings',\n",
    "    'Rural village in a sparse setting': 'Rural Village, Hamlet and Isolated Dwellings',\n",
    "    'Rural hamlets and isolated dwellings': 'Rural Village, Hamlet and Isolated Dwellings',\n",
    "    'Rural hamlets and isolated dwellings in a sparse setting': 'Rural Village, Hamlet and Isolated Dwellings'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the nts Settlement2011EW_B03ID and Settlement2011EW_B04ID columns to the spc\n",
    "spc_edited['Settlement2011EW_B03ID_spc'] = spc_edited['RUC11'].map(census_2011_to_nts_B03ID)\n",
    "spc_edited['Settlement2011EW_B04ID_spc'] = spc_edited['RUC11'].map(census_2011_to_nts_B04ID)\n",
    "spc_edited.head()\n",
    "\n",
    "# add the keys from nts_Settlement2011EW_B03ID and nts_Settlement2011EW_B04ID to the spc based on above mappings\n",
    "\n",
    "# reverse the dictionaries\n",
    "Settlement2011EW_B03ID_nts_rev = {v: k for k, v in Settlement2011EW_B03ID_nts_hh.items()}\n",
    "# map the values\n",
    "spc_edited['Settlement2011EW_B03ID_spc_CD'] = spc_edited['Settlement2011EW_B03ID_spc'].map(Settlement2011EW_B03ID_nts_rev).astype('int')\n",
    "\n",
    "Settlement2011EW_B04ID_nts_rev = {v: k for k, v in Settlement2011EW_B04ID_nts_hh.items()}\n",
    "spc_edited['Settlement2011EW_B04ID_spc_CD'] = spc_edited['Settlement2011EW_B04ID_spc'].map(Settlement2011EW_B04ID_nts_rev).astype('int')\n",
    "spc_edited.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Edit NTS columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of people of pension age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts_pensioners = count_per_group(df = nts_individuals,\n",
    "                                 group_col='HouseholdID',\n",
    "                                 count_col='OfPenAge_B01ID',\n",
    "                                 values=[1],\n",
    "                                 value_names=['num_pension_age_nts'])\n",
    "\n",
    "nts_pensioners.head()\n",
    "\n",
    "# join onto the nts household df\n",
    "nts_households = nts_households.merge(nts_pensioners, left_on='HouseholdID', right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of cars\n",
    "\n",
    "- `SPC.num_cars` only has values [0, 1, 2]. 2 is for all households with 2 or more cars\n",
    "- `NTS.NumCar` is more detailed. It has the actual value of the number of cars. We will cap this at 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a new column in NTS\n",
    "nts_households.loc[:, 'NumCar_SPC_match'] = nts_households['NumCar'].apply(truncate_values, upper = 2)\n",
    "\n",
    "nts_households[['NumCar', 'NumCar_SPC_match']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type of tenancy\n",
    "\n",
    "Breakdown between NTS and SPC is different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_nts['Ten1_B02ID'], dict_spc['tenure']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionaries to map tenure onto the spc and nts dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary showing how we want the final columns to look like\n",
    "tenure_dict_nts_spc = {\n",
    "    1: 'Owned',\n",
    "    2: 'Rented or rent free',\n",
    "    -8: 'NA',\n",
    "    -9: 'DNA',\n",
    "    -10: 'DEAD'\n",
    "}\n",
    "\n",
    "# Matching NTS to tenure_dict_nts_spc\n",
    "\n",
    "# Create a new dictionary for matching\n",
    "matching_dict_nts_tenure = {\n",
    "    1: 1,\n",
    "    2: 2,\n",
    "    3: 2\n",
    "}\n",
    "\n",
    "matching_dict_spc_tenure = {\n",
    "    1: 1, #'Owned: Owned outright' : 'Owned'\n",
    "    2: 1, #'Owned: Owned with a mortgage or loan or shared ownership', : 'Owned'\n",
    "    3: 2, #'Rented or living rent free: Total', : 'Rented or rent free'\n",
    "    4: 2, #'Rented: Social rented', : 'Rented or rent free'\n",
    "    5: 2, #'Rented: Private rented or living rent free', : 'Rented or rent free'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map dictionaries to create comparable columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column in nts_households\n",
    "nts_households['tenure_nts_for_matching'] = (nts_households['Ten1_B02ID']\n",
    "                                                    .map(matching_dict_nts_tenure) # map the values to the new dictionary\n",
    "                                                    .fillna(nts_households['Ten1_B02ID'])) # fill the NaNs with the original values\n",
    "\n",
    "# Create a new column in spc\n",
    "spc_edited['tenure_spc_for_matching'] = (spc_edited['tenure']\n",
    "                                        .map(matching_dict_spc_tenure) # map the values to the new dictionary\n",
    "                                        .fillna(spc_edited['tenure'])) # fill the NaNs with the original values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Matching at Household Level\n",
    "\n",
    "Now that we've prepared all the columns, we can start matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Categorical matching\n",
    "\n",
    "We will match on (a subset of) the following columns:\n",
    "\n",
    "| Matching variable | NTS column | SPC column |\n",
    "| ------------------| ---------- | ---------- |\n",
    "| Household income  | `HHIncome2002_BO2ID` | `salary_yearly_hh_cat` |\n",
    "| Number of adults  | `HHoldNumAdults` | `num_adults` |\n",
    "| Number of children | `HHoldNumChildren` | `num_children` |\n",
    "| Employment status | `HHoldEmploy_B01ID` | `pwkstat_NTS_match` |\n",
    "| Car ownership | `NumCar_SPC_match` | `num_cars` |\n",
    "| Type of tenancy | `tenure_nts_for_matching` | `tenure_spc_for_matching` |\n",
    "| Rural/Urban Classification | `Settlement2011EW_B03ID` | `Settlement2011EW_B03ID_spc_CD` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare SPC df for matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select multiple columns\n",
    "spc_matching = spc_edited[[\n",
    "    'hid',\n",
    "    'salary_yearly_hh_cat', 'num_adults',\n",
    "    'num_children', 'num_pension_age', 'pwkstat_NTS_match',\n",
    "    'num_cars', 'tenure_spc_for_matching',\n",
    "    'Settlement2011EW_B03ID_spc_CD', 'Settlement2011EW_B04ID_spc_CD']]\n",
    "\n",
    "# edit the df so that we have one row per hid\n",
    "spc_matching = spc_matching.drop_duplicates(subset='hid')\n",
    "\n",
    "spc_matching.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare NTS df for matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts_matching = nts_households[[\n",
    "    'HouseholdID','HHIncome2002_B02ID',\n",
    "    'HHoldNumAdults', 'HHoldNumChildren', 'num_pension_age_nts',\n",
    "    'HHoldEmploy_B01ID', 'NumCar_SPC_match',\n",
    "    'tenure_nts_for_matching',\n",
    "    'Settlement2011EW_B03ID', 'Settlement2011EW_B04ID']]\n",
    "\n",
    "nts_matching.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary of matching columns. We extract column names from this dictioary when matching on a subset of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_names (keys) for the dictionary\n",
    "matching_ids = ['household_id', 'yearly_income', 'number_adults', 'number_children', 'num_pension_age',\n",
    "                'employment_status', 'number_cars', 'tenure_status', 'rural_urban_2_categories', 'rural_urban_4_categories']\n",
    "\n",
    "# i want the value to be a list with spc_matching and nts_matching\n",
    "matching_dfs_dict = {column_name: [spc_value, nts_value] for column_name, spc_value, nts_value in zip(matching_ids, spc_matching, nts_matching)}\n",
    "matching_dfs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt 1: Match on all possible columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns for matching\n",
    "keys = ['yearly_income', 'number_adults', 'number_children', 'num_pension_age',\n",
    "        'employment_status', 'number_cars', 'tenure_status', 'rural_urban_2_categories']\n",
    "\n",
    "\n",
    "spc_cols = [matching_dfs_dict[key][0] for key in keys]\n",
    "nts_cols = [matching_dfs_dict[key][1] for key in keys]\n",
    "\n",
    "# match\n",
    "spc_nts_1 = spc_matching.merge(nts_matching,\n",
    "                               left_on= spc_cols,\n",
    "                               right_on= nts_cols,\n",
    "                               how = 'left')\n",
    "\n",
    "# Calculate how many rows from nts_matching are matched onto each hid in spc_matching,\n",
    "spc_nts_1['count'] = spc_nts_1.groupby('hid')['HouseholdID'].transform('count')\n",
    "\n",
    "spc_nts_1_hist = spc_nts_1.drop_duplicates(subset='hid')\n",
    "\n",
    "\n",
    "# plot a histogram of the counts and label the axis and title\n",
    "plt.hist(spc_nts_1_hist['count'], bins=50)\n",
    "plt.xlabel('Number of matches per household')\n",
    "plt.ylabel('Number of households')\n",
    "plt.title('Categorical Matching')\n",
    "\n",
    "print(spc_nts_1_hist[spc_nts_1_hist['count'] == 0].shape[0], \"households in the SPC had no match\")\n",
    "print(round((spc_nts_1_hist[spc_nts_1_hist['count'] == 0].shape[0] / spc_matching['hid'].unique().shape[0]) * 100, 1), \"% of households in the SPC had no match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate matching coverage for all columns\n",
    "\n",
    "match_coverage_1 = {key: match_coverage_col(data=spc_nts_1,\n",
    "                                            id_x='hid',\n",
    "                                            id_y='HouseholdID',\n",
    "                                            column=matching_dfs_dict[key][0])\n",
    "                    for key in matching_dfs_dict\n",
    "            }\n",
    "\n",
    "# extract any df from the list\n",
    "match_coverage_1['number_children']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt 2: Match on a subset of columns (exclude salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns for matching\n",
    "keys = ['number_adults', 'number_children', 'num_pension_age', 'employment_status',\n",
    "        'number_cars', 'tenure_status','rural_urban_2_categories']\n",
    "# extract equivalent column names from dictionary\n",
    "spc_cols = [matching_dfs_dict[key][0] for key in keys]\n",
    "nts_cols = [matching_dfs_dict[key][1] for key in keys]\n",
    "\n",
    "# match\n",
    "spc_nts_2 = spc_matching.merge(nts_matching,\n",
    "                               left_on= spc_cols,\n",
    "                               right_on= nts_cols,\n",
    "                               how = 'left')\n",
    "\n",
    "# Calculate how many rows from nts_matching are matched onto each hid in spc_matching,\n",
    "spc_nts_2['count'] = spc_nts_2.groupby('hid')['HouseholdID'].transform('count')\n",
    "\n",
    "spc_nts_2_hist = spc_nts_2.drop_duplicates(subset='hid')\n",
    "\n",
    "\n",
    "# plot a histogram of the counts and label the axis and title\n",
    "plt.hist(spc_nts_2_hist['count'], bins=50)\n",
    "plt.xlabel('Number of matches per household')\n",
    "plt.ylabel('Number of households')\n",
    "plt.title('Categorical Matching')\n",
    "\n",
    "\n",
    "print(spc_nts_2_hist[spc_nts_2_hist['count'] == 0].shape[0], \"households in the SPC had no match\")\n",
    "print(round((spc_nts_2_hist[spc_nts_2_hist['count'] == 0].shape[0] / spc_matching['hid'].unique().shape[0]) * 100, 1), \"% of households in the SPC had no match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate matching coverage for all columns\n",
    "\n",
    "match_coverage_2 = {key: match_coverage_col(data=spc_nts_2,\n",
    "                                            id_x='hid',\n",
    "                                            id_y='HouseholdID',\n",
    "                                            column=matching_dfs_dict[key][0])\n",
    "                    for key in matching_dfs_dict\n",
    "            }\n",
    "\n",
    "# extract any df from the list\n",
    "#match_coverage_2['number_cars']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt 3: Match on a subset of columns (exclude salary and tenure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# columns for matching\n",
    "keys = ['number_adults', 'number_children', 'num_pension_age', 'employment_status',\n",
    "        'number_cars', 'rural_urban_2_categories']\n",
    "# extract equivalent column names from dictionary\n",
    "spc_cols = [matching_dfs_dict[key][0] for key in keys]\n",
    "nts_cols = [matching_dfs_dict[key][1] for key in keys]\n",
    "\n",
    "# match\n",
    "spc_nts_3 = spc_matching.merge(nts_matching,\n",
    "                               left_on= spc_cols,\n",
    "                               right_on= nts_cols,\n",
    "                               how = 'left')\n",
    "\n",
    "# Calculate how many rows from nts_matching are matched onto each hid in spc_matching,\n",
    "spc_nts_3['count'] = spc_nts_3.groupby('hid')['HouseholdID'].transform('count')\n",
    "\n",
    "spc_nts_3_hist = spc_nts_3.drop_duplicates(subset='hid')\n",
    "\n",
    "\n",
    "# plot a histogram of the counts and label the axis and title\n",
    "plt.hist(spc_nts_3_hist['count'], bins=50)\n",
    "plt.xlabel('Number of matches per household')\n",
    "plt.ylabel('Number of households')\n",
    "plt.title('Categorical Matching')\n",
    "\n",
    "\n",
    "print(spc_nts_3_hist[spc_nts_3_hist['count'] == 0].shape[0], \"households in the SPC had no match\")\n",
    "print(round((spc_nts_3_hist[spc_nts_3_hist['count'] == 0].shape[0] / spc_matching['hid'].unique().shape[0]) * 100, 1), \"% of households in the SPC had no match\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate matching coverage for all columns\n",
    "\n",
    "match_coverage_3 = {key: match_coverage_col(data=spc_nts_3,\n",
    "                                            id_x='hid',\n",
    "                                            id_y='HouseholdID',\n",
    "                                            column=matching_dfs_dict[key][0])\n",
    "                    for key in matching_dfs_dict\n",
    "            }\n",
    "\n",
    "# extract any df from the list\n",
    "#match_coverage_2['number_cars']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt 4: Match on a subset of columns (exclude salary, tenure, and employment status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# columns for matching\n",
    "keys = ['number_adults', 'number_children', 'num_pension_age', 'number_cars', 'rural_urban_2_categories']\n",
    "# extract equivalent column names from dictionary\n",
    "spc_cols = [matching_dfs_dict[key][0] for key in keys]\n",
    "nts_cols = [matching_dfs_dict[key][1] for key in keys]\n",
    "\n",
    "# matc\n",
    "spc_nts_4 = spc_matching.merge(nts_matching,\n",
    "                               left_on= spc_cols,\n",
    "                               right_on= nts_cols,\n",
    "                               how = 'left')\n",
    "\n",
    "# Calculate how many rows from nts_matching are matched onto each hid in spc_matching,\n",
    "spc_nts_4['count'] = spc_nts_4.groupby('hid')['HouseholdID'].transform('count')\n",
    "\n",
    "spc_nts_4_hist = spc_nts_4.drop_duplicates(subset='hid')\n",
    "\n",
    "\n",
    "# plot a histogram of the counts and label the axis and title\n",
    "plt.hist(spc_nts_4_hist['count'], bins=50)\n",
    "plt.xlabel('Number of matches per household')\n",
    "plt.ylabel('Number of households')\n",
    "plt.title('Categorical Matching')\n",
    "\n",
    "\n",
    "print(spc_nts_4_hist[spc_nts_4_hist['count'] == 0].shape[0], \"households in the SPC had no match\")\n",
    "print(round((spc_nts_4_hist[spc_nts_4_hist['count'] == 0].shape[0] / spc_matching['hid'].unique().shape[0]) * 100, 1), \"% of households in the SPC had no match\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate matching coverage for all columns\n",
    "\n",
    "match_coverage_4 = {key: match_coverage_col(data=spc_nts_4,\n",
    "                                            id_x='hid',\n",
    "                                            id_y='HouseholdID',\n",
    "                                            column=matching_dfs_dict[key][0])\n",
    "                    for key in matching_dfs_dict\n",
    "            }\n",
    "\n",
    "# extract any df from the list\n",
    "#match_coverage_2['number_cars']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing salary has a significant impact on matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spc_matching['hid'].nunique(), \"Total households in SPC\")\n",
    "\n",
    "# Attempt 1\n",
    "print(spc_nts_1_hist[spc_nts_1_hist['count'] == 0].shape[0], \"Unmatched households - matching on all categories\")\n",
    "# Attempt 2\n",
    "print(spc_nts_2_hist[spc_nts_2_hist['count'] == 0].shape[0], \"Unmatched households - exclusing Salary from matching\")\n",
    "# Attempt 3\n",
    "print(spc_nts_3_hist[spc_nts_3_hist['count'] == 0].shape[0], \"Unmatched households - exclusing Salary and Tenure from matching\")\n",
    "# Attempt 4\n",
    "print(spc_nts_4_hist[spc_nts_4_hist['count'] == 0].shape[0], \"Unmatched households - exclusing Salary, Tenure and Employment status from matching\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot matching coverage for each attempt + variable (key) combination\n",
    "\n",
    "This will show us, for each matching key, the % of spc households from each unique category that were matched to the NTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make plots path\n",
    "os.makedirs(\"../data/interim/matching/plots/\", exist_ok=True)\n",
    "\n",
    "# loop over all variables in matching_dfs_dict and save a plot for each\n",
    "for key in list(matching_dfs_dict.keys())[1:]:      # skip 1st key (hid)\n",
    "    x = (match_coverage_1[key]\n",
    "     .merge(match_coverage_2[key], on=matching_dfs_dict[key][0], suffixes=('_1', '_2'))\n",
    "     .merge(match_coverage_3[key], on=matching_dfs_dict[key][0], suffixes=('_2', '_3'))\n",
    "     .merge(match_coverage_4[key], on=matching_dfs_dict[key][0], suffixes=('_3', '_4')))\n",
    "    # keep % columns only\n",
    "    x = x[[col for col in x.columns if 'Percentage' in col]]\n",
    "    # plot bar chart of Percentage of households matched for each category\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "    x.plot(kind='bar', ax=ax)\n",
    "    plt.ylabel('% of households matched')\n",
    "    plt.title('Matching coverage for ' + key)\n",
    "    plt.show()\n",
    "    # save the plot\n",
    "    fig.savefig(f'../data/interim/matching/plots/matching_coverage_hh_{key}.png')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot matching coverage for each attempt + variable (key) combination\n",
    "\n",
    "This will show us, for each matching key, the % of spc households from each unique category that were matched to the NTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all variables in matching_dfs_dict and save a plot for each\n",
    "for key in list(matching_dfs_dict.keys())[1:]:      # skip 1st key (hid)\n",
    "    x = (match_coverage_1[key]\n",
    "     .merge(match_coverage_2[key], on=matching_dfs_dict[key][0], suffixes=('_1', '_2'))\n",
    "     .merge(match_coverage_3[key], on=matching_dfs_dict[key][0], suffixes=('_2', '_3'))\n",
    "     .merge(match_coverage_4[key], on=matching_dfs_dict[key][0], suffixes=('_3', '_4')))\n",
    "    # keep % columns only\n",
    "    x = x[[col for col in x.columns if 'Percentage' in col]]\n",
    "    # plot bar chart of Percentage of households matched for each category\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "    x.plot(kind='bar', ax=ax)\n",
    "    plt.ylabel('% of households matched')\n",
    "    plt.title('Matching coverage for ' + key)\n",
    "    plt.show()\n",
    "    # save the plot\n",
    "    fig.savefig(f'../data/interim/matching/plots/matching_coverage_hh_{key}.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treat different households differently\n",
    "\n",
    "Salary is a useful matching variable, so it's a shame not to use it all. We can try to:\n",
    "- match on salary for households with 0 pensioners\n",
    "- match without salary for households with one or more pensioners "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match on different subset of column depending on yearly_income value\n",
    "keys = ['yearly_income', 'number_adults', 'number_children', 'num_pension_age',\n",
    "        'employment_status', 'number_cars', 'tenure_status', 'rural_urban_2_categories']\n",
    "# remove yearly income from the list\n",
    "# new list without yearly income, without modifying the original list\n",
    "keys_no_salary = keys.copy()\n",
    "keys_no_salary.remove('yearly_income')\n",
    "\n",
    "\n",
    "#### ------ Split the two datasets into households with no salary and households with a salary\n",
    "\n",
    "# get spc column name that matches yearly_income in matching_dfs_dict\n",
    "spc_col = matching_dfs_dict['num_pension_age'][0]\n",
    "nts_col = matching_dfs_dict['num_pension_age'][1]\n",
    "\n",
    "# dfs: households with no salary\n",
    "spc_matching_no_salary = spc_matching[spc_matching[spc_col] > 0]\n",
    "nts_matching_no_salary = nts_matching[nts_matching[nts_col] > 0]\n",
    "\n",
    "# dfs: households with a salary\n",
    "spc_matching_salary = spc_matching[spc_matching[spc_col] != 0]\n",
    "nts_matching_salary = nts_matching[nts_matching[nts_col] != 0]\n",
    "\n",
    "\n",
    "#### ------ Match the two datasets separately\n",
    "\n",
    "# extract equivalent column names from dictionary\n",
    "spc_cols = [matching_dfs_dict[key][0] for key in keys]\n",
    "nts_cols = [matching_dfs_dict[key][1] for key in keys]\n",
    "\n",
    "# extract equivalent column names from dictionary\n",
    "spc_cols_no_salary = [matching_dfs_dict[key][0] for key in keys_no_salary]\n",
    "nts_cols_no_salary = [matching_dfs_dict[key][1] for key in keys_no_salary]\n",
    "\n",
    "# match\n",
    "spc_nts_no_salary = spc_matching_no_salary.merge(nts_matching_no_salary,\n",
    "                                                 left_on= spc_cols_no_salary,\n",
    "                                                 right_on= nts_cols_no_salary,\n",
    "                                                 how = 'left')\n",
    "\n",
    "spc_nts_salary = spc_matching_salary.merge(nts_matching_salary,\n",
    "                                           left_on= spc_cols,\n",
    "                                           right_on= nts_cols,\n",
    "                                           how = 'left')\n",
    "\n",
    "# bind the rows of the two dataframes\n",
    "spc_nts_x = pd.concat([spc_nts_no_salary, spc_nts_salary])\n",
    "\n",
    "\n",
    "# Calculate how many rows from nts_matching are matched onto each hid in spc_matching,\n",
    "spc_nts_x['count'] = spc_nts_x.groupby('hid')['HouseholdID'].transform('count')\n",
    "\n",
    "spc_nts_x_hist = spc_nts_x.drop_duplicates(subset='hid')\n",
    "\n",
    "\n",
    "# plot a histogram of the counts and label the axis and title\n",
    "plt.hist(spc_nts_x_hist['count'], bins=50)\n",
    "plt.xlabel('Number of matches per household')\n",
    "plt.ylabel('Number of households')\n",
    "plt.title('Categorical Matching')\n",
    "\n",
    "\n",
    "print(spc_nts_x_hist[spc_nts_x_hist['count'] == 0].shape[0], \"households in the SPC had no match\")\n",
    "print(round((spc_nts_x_hist[spc_nts_x_hist['count'] == 0].shape[0] / spc_matching['hid'].unique().shape[0]) * 100, 1), \"% of households in the SPC had no match\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acbm-7iKwKWLy-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
