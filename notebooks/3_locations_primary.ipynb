{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Primary Location to individuals\n",
    "\n",
    "After assigning an activity chain to each individual, we then need to map these activities to geographic locations. We start with primary locations (work, school) and fill in the gaps later with discretionary locations. This notebook will focus on the primary locations.\n",
    "\n",
    "We follow the steps outlined in this [github issue](https://github.com/Urban-Analytics-Technology-Platform/acbm/issues/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'fill_missing_zones' from 'acbm.assigning' (/home/hussein/Documents/GitHub/acbm/src/acbm/assigning/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Point\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01macbm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massigning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     12\u001b[0m     fill_missing_zones,\n\u001b[1;32m     13\u001b[0m     get_activities_per_zone,\n\u001b[1;32m     14\u001b[0m     get_possible_zones,\n\u001b[1;32m     15\u001b[0m     select_zone,\n\u001b[1;32m     16\u001b[0m     zones_to_time_matrix,\n\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'fill_missing_zones' from 'acbm.assigning' (/home/hussein/Documents/GitHub/acbm/src/acbm/assigning/__init__.py)"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pickle as pkl\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from acbm.assigning import (\n",
    "    fill_missing_zones,\n",
    "    get_activities_per_zone,\n",
    "    get_possible_zones,\n",
    "    select_zone,\n",
    "    zones_to_time_matrix,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>household</th>\n",
       "      <th>pid_hs</th>\n",
       "      <th>msoa11cd</th>\n",
       "      <th>oa11cd</th>\n",
       "      <th>members</th>\n",
       "      <th>sic1d2007</th>\n",
       "      <th>sic2d2007</th>\n",
       "      <th>pwkstat</th>\n",
       "      <th>salary_yearly</th>\n",
       "      <th>...</th>\n",
       "      <th>tst</th>\n",
       "      <th>tet</th>\n",
       "      <th>TripDisIncSW</th>\n",
       "      <th>TripDisExSW</th>\n",
       "      <th>TripTotalTime</th>\n",
       "      <th>TripTravTime</th>\n",
       "      <th>ozone</th>\n",
       "      <th>dzone</th>\n",
       "      <th>W5</th>\n",
       "      <th>W5xHH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199</td>\n",
       "      <td>89</td>\n",
       "      <td>2906098</td>\n",
       "      <td>E02002330</td>\n",
       "      <td>E00059031</td>\n",
       "      <td>[199, 200, 201]</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>21491.294922</td>\n",
       "      <td>...</td>\n",
       "      <td>390.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.568328</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199</td>\n",
       "      <td>89</td>\n",
       "      <td>2906098</td>\n",
       "      <td>E02002330</td>\n",
       "      <td>E00059031</td>\n",
       "      <td>[199, 200, 201]</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>21491.294922</td>\n",
       "      <td>...</td>\n",
       "      <td>990.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.568328</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199</td>\n",
       "      <td>89</td>\n",
       "      <td>2906098</td>\n",
       "      <td>E02002330</td>\n",
       "      <td>E00059031</td>\n",
       "      <td>[199, 200, 201]</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>21491.294922</td>\n",
       "      <td>...</td>\n",
       "      <td>520.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.568328</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199</td>\n",
       "      <td>89</td>\n",
       "      <td>2906098</td>\n",
       "      <td>E02002330</td>\n",
       "      <td>E00059031</td>\n",
       "      <td>[199, 200, 201]</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>21491.294922</td>\n",
       "      <td>...</td>\n",
       "      <td>530.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.568328</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199</td>\n",
       "      <td>89</td>\n",
       "      <td>2906098</td>\n",
       "      <td>E02002330</td>\n",
       "      <td>E00059031</td>\n",
       "      <td>[199, 200, 201]</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>21491.294922</td>\n",
       "      <td>...</td>\n",
       "      <td>890.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.568328</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>199</td>\n",
       "      <td>89</td>\n",
       "      <td>2906098</td>\n",
       "      <td>E02002330</td>\n",
       "      <td>E00059031</td>\n",
       "      <td>[199, 200, 201]</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>21491.294922</td>\n",
       "      <td>...</td>\n",
       "      <td>905.0</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.568328</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>199</td>\n",
       "      <td>89</td>\n",
       "      <td>2906098</td>\n",
       "      <td>E02002330</td>\n",
       "      <td>E00059031</td>\n",
       "      <td>[199, 200, 201]</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>21491.294922</td>\n",
       "      <td>...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.633716</td>\n",
       "      <td>1.115053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>199</td>\n",
       "      <td>89</td>\n",
       "      <td>2906098</td>\n",
       "      <td>E02002330</td>\n",
       "      <td>E00059031</td>\n",
       "      <td>[199, 200, 201]</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>21491.294922</td>\n",
       "      <td>...</td>\n",
       "      <td>645.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.633716</td>\n",
       "      <td>1.115053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>199</td>\n",
       "      <td>89</td>\n",
       "      <td>2906098</td>\n",
       "      <td>E02002330</td>\n",
       "      <td>E00059031</td>\n",
       "      <td>[199, 200, 201]</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>21491.294922</td>\n",
       "      <td>...</td>\n",
       "      <td>720.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.639694</td>\n",
       "      <td>1.125570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>199</td>\n",
       "      <td>89</td>\n",
       "      <td>2906098</td>\n",
       "      <td>E02002330</td>\n",
       "      <td>E00059031</td>\n",
       "      <td>[199, 200, 201]</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>21491.294922</td>\n",
       "      <td>...</td>\n",
       "      <td>765.0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.639694</td>\n",
       "      <td>1.125570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  household   pid_hs   msoa11cd     oa11cd          members sic1d2007  \\\n",
       "0  199         89  2906098  E02002330  E00059031  [199, 200, 201]         C   \n",
       "1  199         89  2906098  E02002330  E00059031  [199, 200, 201]         C   \n",
       "2  199         89  2906098  E02002330  E00059031  [199, 200, 201]         C   \n",
       "3  199         89  2906098  E02002330  E00059031  [199, 200, 201]         C   \n",
       "4  199         89  2906098  E02002330  E00059031  [199, 200, 201]         C   \n",
       "5  199         89  2906098  E02002330  E00059031  [199, 200, 201]         C   \n",
       "6  199         89  2906098  E02002330  E00059031  [199, 200, 201]         C   \n",
       "7  199         89  2906098  E02002330  E00059031  [199, 200, 201]         C   \n",
       "8  199         89  2906098  E02002330  E00059031  [199, 200, 201]         C   \n",
       "9  199         89  2906098  E02002330  E00059031  [199, 200, 201]         C   \n",
       "\n",
       "   sic2d2007  pwkstat  salary_yearly  ...    tst     tet  TripDisIncSW  \\\n",
       "0       26.0        1   21491.294922  ...  390.0   410.0          13.0   \n",
       "1       26.0        1   21491.294922  ...  990.0  1020.0          13.0   \n",
       "2       26.0        1   21491.294922  ...  520.0   525.0           1.0   \n",
       "3       26.0        1   21491.294922  ...  530.0   535.0           1.0   \n",
       "4       26.0        1   21491.294922  ...  890.0   900.0           1.0   \n",
       "5       26.0        1   21491.294922  ...  905.0   910.0           1.0   \n",
       "6       26.0        1   21491.294922  ...  600.0   645.0           6.0   \n",
       "7       26.0        1   21491.294922  ...  645.0   690.0           6.0   \n",
       "8       26.0        1   21491.294922  ...  720.0   730.0           1.0   \n",
       "9       26.0        1   21491.294922  ...  765.0   775.0           1.0   \n",
       "\n",
       "   TripDisExSW  TripTotalTime  TripTravTime  ozone  dzone        W5     W5xHH  \n",
       "0         13.0           20.0          20.0    2.0    2.0  0.568328  1.000000  \n",
       "1         13.0           30.0          20.0    2.0    2.0  0.568328  1.000000  \n",
       "2          1.0            5.0           5.0    2.0    2.0  0.568328  1.000000  \n",
       "3          1.0            5.0           5.0    2.0    2.0  0.568328  1.000000  \n",
       "4          1.0           10.0           5.0    2.0    2.0  0.568328  1.000000  \n",
       "5          1.0            5.0           5.0    2.0    2.0  0.568328  1.000000  \n",
       "6          6.0           45.0          45.0    2.0    2.0  0.633716  1.115053  \n",
       "7          6.0           45.0          45.0    2.0    2.0  0.633716  1.115053  \n",
       "8          1.0           10.0          10.0    2.0    2.0  0.639694  1.125570  \n",
       "9          1.0           10.0          10.0    2.0    2.0  0.639694  1.125570  \n",
       "\n",
       "[10 rows x 70 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read parquet file\n",
    "activity_chains = pd.read_parquet('../data/interim/matching/spc_with_nts_trips.parquet')\n",
    "activity_chains.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation: Mapping trip purposes\n",
    "\n",
    "Rename columns and map actual modes and trip purposes to the trip table. \n",
    "\n",
    "Code taken from: https://github.com/arup-group/pam/blob/main/examples/07_travel_survey_to_matsim.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "activity_chains = activity_chains.rename(\n",
    "    columns={  # rename data\n",
    "        \"JourSeq\": \"seq\",\n",
    "        \"TripOrigGOR_B02ID\": \"ozone\",\n",
    "        \"TripDestGOR_B02ID\": \"dzone\",\n",
    "        \"TripPurpFrom_B01ID\": \"oact\",\n",
    "        \"TripPurpTo_B01ID\": \"dact\",\n",
    "        \"MainMode_B04ID\": \"mode\",\n",
    "        \"TripStart\": \"tst\",\n",
    "        \"TripEnd\": \"tet\",\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the NTS glossary [here](https://www.gov.uk/government/statistics/national-travel-survey-2022-technical-report/national-travel-survey-2022-technical-report-glossary) to understand what the trip purposes mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add an escort column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "mode_mapping = {\n",
    "    1: \"walk\",\n",
    "    2: \"cycle\",\n",
    "    3: \"car\",  #'Car/van driver'\n",
    "    4: \"car\",  #'Car/van driver'\n",
    "    5: \"car\",  #'Motorcycle',\n",
    "    6: \"car\",  #'Other private transport',\n",
    "    7: \"pt\",  # Bus in London',\n",
    "    8: \"pt\",  #'Other local bus',\n",
    "    9: \"pt\",  #'Non-local bus',\n",
    "    10: \"pt\",  #'London Underground',\n",
    "    11: \"pt\",  #'Surface Rail',\n",
    "    12: \"car\",  #'Taxi/minicab',\n",
    "    13: \"pt\",  #'Other public transport',\n",
    "    -10: \"DEAD\",\n",
    "    -8: \"NA\",\n",
    "}\n",
    "\n",
    "purp_mapping = {\n",
    "    1: \"work\",\n",
    "    2: \"work\",  #'In course of work',\n",
    "    3: \"education\",\n",
    "    4: \"shop_food\",  #'Food shopping',\n",
    "    5: \"shop_other\",  #'Non food shopping',\n",
    "    6: \"medical\",  #'Personal business medical',\n",
    "    7: \"other_eat_drink\",  #'Personal business eat/drink',\n",
    "    8: \"other\",  #'Personal business other',\n",
    "    9: \"other_eat_drink\",  #'Eat/drink with friends',\n",
    "    10: \"visit\",  #'Visit friends',\n",
    "    11: \"other_social\",  #'Other social',\n",
    "    12: \"other\",  #'Entertain/ public activity',\n",
    "    13: \"other_sport\",  #'Sport: participate',\n",
    "    14: \"home\",  #'Holiday: base',\n",
    "    15: \"other\",  #'Day trip/just walk',\n",
    "    16: \"other\",  #'Other non-escort',\n",
    "    17: \"escort_home\",  #'Escort home',\n",
    "    18: \"escort_work\",  #'Escort work',\n",
    "    19: \"escort_work\",  #'Escort in course of work',\n",
    "    20: \"escort_education\",  #'Escort education',\n",
    "    21: \"escort_shopping\",  #'Escort shopping/personal business',\n",
    "    22: \"escort\",  #'Other escort',\n",
    "    23: \"home\",  #'Home',\n",
    "    -10: \"DEAD\",\n",
    "    -8: \"NA\",\n",
    "}\n",
    "\n",
    "# TODO: Original recoding, no longer required to be applied, consider removing from here\n",
    "# activity_chains[\"mode\"] = activity_chains[\"mode\"].map(mode_mapping)\n",
    "# activity_chains[\"oact\"] = activity_chains[\"oact\"].map(purp_mapping)\n",
    "# activity_chains[\"dact\"] = activity_chains[\"dact\"].map(purp_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study area boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "boundaries = gpd.read_file('../data/external/boundaries/oa_england.geojson')\n",
    "boundaries.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# filter to only include the OA's where \"Leeds\" is in the MSOA21NM field\n",
    "boundaries = boundaries[boundaries['MSOA21NM'].str.contains(\"Leeds\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# convert boundaries to 4326\n",
    "boundaries = boundaries.to_crs(epsg=4326)\n",
    "# plot the geometry\n",
    "boundaries.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "boundaries.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign activity home locations to boundaries zoning system "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert location column in activity_chains to spatial column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn column to shapely point\n",
    "def add_location(df):\n",
    "    from shapely.geometry import Point\n",
    "    from pyproj import Transformer\n",
    "\n",
    "    # source and target CRS\n",
    "    source, target = \"EPSG:27700\", \"EPSG:4326\"\n",
    "    # read centroids in source CRS\n",
    "    location = pd.read_csv(\n",
    "        \"../data/external/centroids/Output_Areas_Dec_2011_PWC_2022.csv\"\n",
    "    )\n",
    "    # make transformer\n",
    "    transformer = Transformer.from_crs(source, target, always_xy=True)\n",
    "\n",
    "    # convert loc from source to target CRS returning as Point type\n",
    "    def get_new_coords(loc):\n",
    "        x, y = transformer.transform(loc[\"x\"], loc[\"y\"])\n",
    "        return Point(x, y)\n",
    "\n",
    "    location[\"location\"] = location.apply(lambda loc: get_new_coords(loc), axis=1)\n",
    "    return df.merge(\n",
    "        location[[\"OA11CD\", \"location\"]], left_on=\"OA11CD\", right_on=\"OA11CD\"\n",
    "    )\n",
    "\n",
    "\n",
    "activity_chains = add_location(activity_chains)\n",
    "\n",
    "\n",
    "# Convert the DataFrame into a GeoDataFrame, and assign a coordinate reference system (CRS)\n",
    "activity_chains = gpd.GeoDataFrame(activity_chains, geometry=\"location\")\n",
    "activity_chains.crs = \"EPSG:4326\"  # I assume this is the crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# plot the boundaries gdf and overlay them with the activity_chains gdf\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "boundaries.plot(ax=ax, color='lightgrey')\n",
    "activity_chains.plot(ax=ax, color='red', markersize=1)\n",
    "plt.title('Activity Chains overlaid on Leeds Output Areas')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#remove index_right column from activity_chains if it exists\n",
    "if 'index_right' in activity_chains.columns:\n",
    "    activity_chains = activity_chains.drop(columns='index_right')\n",
    "\n",
    "\n",
    "# Spatial join to identify which polygons each point is in\n",
    "activity_chains = gpd.sjoin(activity_chains, boundaries[[\"OA21CD\", \"geometry\"]], how='left', predicate='within')\n",
    "activity_chains = activity_chains.drop('index_right', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Travel time matrix for study area\n",
    "\n",
    "Travel time data between geographical areas (LSOA, OA, custom hexagons etc) is used to determine feasible work / school locations for each individual. The travel times are compared to the travel times of the individual's actual trips from the nts (`tst`/`TripStart` and `tet`/`TripEnd`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "travel_times = pd.read_parquet('../data/external/travel_times/oa/travel_time_matrix_acbm.parquet')\n",
    "travel_times.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "travel_times[\"combination\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add area code to travel time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# convert from_id and to_id to int to match the boundaries data type\n",
    "travel_times = travel_times.astype({'from_id': int, 'to_id': int})\n",
    "\n",
    "# merge travel_times with boundaries\n",
    "travel_times = travel_times.merge(boundaries[['OBJECTID', 'OA21CD']], left_on='from_id', right_on='OBJECTID', how='left')\n",
    "travel_times = travel_times.drop(columns='OBJECTID')\n",
    "\n",
    "travel_times = travel_times.merge(boundaries[['OBJECTID', 'OA21CD']], left_on='to_id', right_on='OBJECTID', how='left', suffixes=('_from', '_to'))\n",
    "travel_times = travel_times.drop(columns='OBJECTID')\n",
    "\n",
    "travel_times.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Travel distance matrix\n",
    "\n",
    "Some areas aren't reachable by specific modes. This can cause problems later on in get_possible_zones() as we won't be able to assign some activities to zones. We create a travel distance matrix to fall back on when there are no travel time calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_time_estimates = zones_to_time_matrix(\n",
    "    zones = boundaries,\n",
    "    id_col = \"OA21CD\",\n",
    "    to_dict = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an iterator over the dictionary items and then print the first n items\n",
    "items = iter(travel_time_estimates.items())\n",
    "\n",
    "for i in range(5):\n",
    "    print(next(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/interim/assigning/travel_time_estimates.pkl', 'wb') as f:\n",
    "    pkl.dump(travel_time_estimates, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity locations \n",
    "\n",
    "Activity locations are obtained from OSM using the [osmox](https://github.com/arup-group/osmox) package. Check the config documentation in the package and the `config_osmox` file in this repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# osm data\n",
    "osm_data = gpd.read_parquet('../data/external/boundaries/west-yorkshire_epsg_4326.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "osm_data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# get unique values for activties column\n",
    "osm_data['activities'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# remove rows with activities = home\n",
    "\n",
    "osm_data = osm_data[osm_data['activities'] != 'home']\n",
    "osm_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "osm_data.activities.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the number of activities in each zone \n",
    "\n",
    "Each zone has a different number of education facilities. We can use the number of facilities in each zone to determine the probability of each zone being chosen for each trip. We can then use these probabilities to randomly assign a zone to each trip.\n",
    "\n",
    "The education facilities are disaggregated by type. For each activity, we use the individual's age to detemrine which of the following they are most likely to go to \n",
    "\n",
    "- \"kindergarden\": education_kg\"\n",
    "- \"school\": \"education_school\"\n",
    "- \"university\": \"education_university\"\n",
    "- \"college\": \"education_college\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# spatial join to identify which zone each point in osm_data is in\n",
    "osm_data_gdf = gpd.sjoin(osm_data, boundaries[[\"OA21CD\", \"geometry\"]], how='inner', predicate='within')\n",
    "osm_data_gdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# plot the points and then plot the zones on a map\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "boundaries.plot(ax=ax, color='lightgrey')\n",
    "osm_data_gdf.plot(ax=ax, color='red', markersize=1)\n",
    "plt.title('OSM Data overlaid on Leeds Output Areas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if we can use floor area as a weight when sampling a region / a school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# plot the distribution of floor area for rows where activities includes \"education_\"\n",
    "\n",
    "\n",
    "# List of activity types\n",
    "activity_types = ['education_kg', 'education_school', 'education_university', 'education_college']\n",
    "\n",
    "# Initialize a list to store DataFrames\n",
    "df_list = []\n",
    "\n",
    "# For each activity type, filter the rows where activities includes the activity type, and append to df_list\n",
    "for activity in activity_types:\n",
    "    temp_df = osm_data_gdf[osm_data_gdf['activities'].apply(lambda x: activity in x)][['floor_area']].copy()\n",
    "    temp_df['activity'] = activity\n",
    "    df_list.append(temp_df)\n",
    "\n",
    "# Concatenate all the DataFrames in df_list\n",
    "df = pd.concat(df_list)\n",
    "\n",
    "# Create a FacetGrid\n",
    "g = sns.FacetGrid(df, col=\"activity\", col_wrap=2, sharex=False)\n",
    "g.map(sns.histplot, \"floor_area\", bins=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select a zone from a list of zones, we need a list of the activity types that are available in the zone. We then sample probabilistically based on number of activities / total floorspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_activities_per_zone()` can return a dictionary of dfs, or one big df. Just set `return_df` to `True` to get one df. Let's try both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "activities_per_zone_dict = get_activities_per_zone(\n",
    "    zones = boundaries,\n",
    "    zone_id_col = \"OA21CD\",\n",
    "    activity_pts = osm_data,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an iterator over the dictionary items\n",
    "items = iter(activities_per_zone_dict.items())\n",
    "\n",
    "# Print the first 5 items\n",
    "for i in range(5):\n",
    "    print(next(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_per_zone = get_activities_per_zone(\n",
    "    zones = boundaries,\n",
    "    zone_id_col = \"OA21CD\",\n",
    "    activity_pts = osm_data,\n",
    "    return_df = True\n",
    "    )\n",
    "\n",
    "activities_per_zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/interim/assigning/activities_per_zone.pkl', 'wb') as f:\n",
    "    pkl.dump(activities_per_zone_dict, f)\n",
    "\n",
    "# save activities_per_zone as a parquet file\n",
    "activities_per_zone.to_parquet('../data/interim/assigning/activities_per_zone.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Education\n",
    "\n",
    "The NTS gives us the trip duration, mode, and trip purpose of each activity. We have also calculated a zone to zone travel time matrix by mode. We know the locaiton of people's homes so, for home-based activities, we can use this information to determine the feasible zones for each activity.\n",
    "\n",
    "- Determine activity origin zone, mode, and duration (these are the constraints)\n",
    "- Filter travel time matrix to include only destinations that satisfy all constraints. These are the feasible zones\n",
    "- If there are no feasible zones, select the zone with the closest travel time to the reported duration\n",
    "\n",
    "We start with `education` trips as we need to know the trip origin. The vast majority of `education` trips start at home, as shown in `3.1_sandbox-locations_primary.ipynb`. Given that we know the home location of each individual, we can use this information to determine the feasible zones for each education trip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting feasible zones for each activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "print(activity_chains[\"dact\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_chains_edu = activity_chains[activity_chains['dact'] == 'education']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For education trips, we use age as an indicator for the type of education facility the individual is most likely to go to. The `age_group_mapping` dictionary maps age groups to education facility types. For each person activity, we use the age_group to determine which education facilities to look at. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the age_group to an education type (age group is from NTS::Age_B04ID)\n",
    "# TODO edit osmox config to replace education_college with education_university.\n",
    "# We should have mutually exclusive groups only and these two options serve the\n",
    "# same age group\n",
    "age_group_mapping = {\n",
    "    1: \"education_kg\",   # \"0-4\"\n",
    "    2: \"education_school\", # \"5-10\"\n",
    "    3: \"education_school\", # \"11-16\"\n",
    "    4: \"education_university\", # \"17-20\"\n",
    "    5: \"education_university\", # \"21-29\"\n",
    "    6: \"education_university\", # \"30-39\"\n",
    "    7: \"education_university\", # \"40-49\"\n",
    "    8: \"education_university\", # \"50-59\"\n",
    "    9: \"education_university\" # \"60+\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: age_group mapping onto education type\n",
    "\n",
    "# map the age_group_mapping dict to an education type (age group is from NTS::Age_B04ID)\n",
    "activity_chains_edu[\"education_type\"] = activity_chains_edu[\"age_group\"].map(age_group_mapping)\n",
    "activity_chains_edu.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_zones_school = get_possible_zones(activity_chains=activity_chains_edu,\n",
    "                                           travel_times=travel_times,\n",
    "                                           activities_per_zone = activities_per_zone,\n",
    "                                           filter_by_activity=True,\n",
    "                                           activity_col= \"education_type\",\n",
    "                                           time_tolerance=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output is a nested dictionary\n",
    "for key in list(possible_zones_school.keys())[:10]:\n",
    "    print(key, ' : ', possible_zones_school[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save possible_zones_school to dictionary\n",
    "with open('../data/interim/assigning/possible_zones_education.pkl', 'wb') as f:\n",
    "    pkl.dump(possible_zones_school, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# remove possible_zones_school from environment\n",
    "#del possible_zones_school\n",
    "\n",
    "# read in possible_zones_school\n",
    "possible_zones_school = pd.read_pickle('../data/interim/assigning/possible_zones_education.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a zone for each activity\n",
    "\n",
    "We choose a zone from the feasible zones. For education trips, we use age as an indicator for the type of education facility the individual is most likely to go to. The `age_group_mapping` dictionary maps age groups to education facility types. For each person activity, we use the age_group to determine which education facilities to look at. \n",
    "\n",
    "We then sample probabilistically based on the number of facilities in each zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to all rows in activity_chains_example\n",
    "activity_chains_edu['dzone'] = activity_chains_edu.apply(\n",
    "    lambda row: select_zone(\n",
    "        row=row,\n",
    "        possible_zones = possible_zones_school,\n",
    "        activities_per_zone = activities_per_zone,\n",
    "        weighting = \"floor_area\",\n",
    "        zone_id_col = \"OA21CD\"\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_chains_edu.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total rows and number of rows with NA in dzone\n",
    "print(f\"Total rows: {activity_chains_edu.shape[0]}\")\n",
    "print(f\"Number of rows with NA in dzone: {activity_chains_edu[activity_chains_edu['dzone'] == 'NA'].shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activity_chains_edu[activity_chains_edu['dzone'] == 'NA']\n",
    "# what is the mode of the rows with NA in dzone\n",
    "activity_chains_edu[activity_chains_edu['dzone'] == 'NA']['mode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the issue seems to be with walking trips. Let's look further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows in activity_chains_edu with dzone = NA and mode = walk\n",
    "filtered_data = activity_chains_edu[(activity_chains_edu['dzone'] == 'NA') & (activity_chains_edu['mode'] == 'walk')]\n",
    "\n",
    "# Create bins for TripTotalTime\n",
    "filtered_data['TripTotalTime_bins'] = pd.cut(filtered_data['TripTotalTime'], bins=range(0, int(filtered_data['TripTotalTime'].max()) + 5, 5))\n",
    "\n",
    "# Group by TripTotalTime_bins and education_type\n",
    "grouped_data = filtered_data.groupby(['TripTotalTime_bins', 'education_type']).size()\n",
    "\n",
    "# Remove groups with zero counts\n",
    "grouped_data = grouped_data[grouped_data > 0]\n",
    "\n",
    "# Print the grouped data\n",
    "print(grouped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in missing zones\n",
    "\n",
    "Some activities are not assigned a zone because there is no zone that (a) has the activity, and (b) is reachable using the reprted mode and duration (based on travel_time matrix r5 calculations). For these rows, we fill the zone using times based on euclidian distance and estimated speeds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for rows where 'dzone' is NaN\n",
    "mask = activity_chains_edu['dzone'] == 'NA'\n",
    "\n",
    "# Apply the function to these rows and assign the result back to 'dzone'\n",
    "activity_chains_edu.loc[mask, 'dzone'] = activity_chains_edu.loc[mask].apply(\n",
    "    lambda row: fill_missing_zones(\n",
    "        activity=row,\n",
    "        travel_times_est=travel_time_estimates,\n",
    "        activities_per_zone=activities_per_zone,\n",
    "        activity_col=\"education_type\",\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total rows and number of rows with NA in dzone\n",
    "print(f\"Total rows: {activity_chains_edu.shape[0]}\")\n",
    "print(f\"Number of rows with NA in dzone: {activity_chains_edu[activity_chains_edu['dzone'] == 'NA'].shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Assign activity to point locations\n",
    "\n",
    "After choosing a zone, let's assign the activity to a point location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# turn the above into a function\n",
    "def select_activity(row: pd.Series,\n",
    "                    activities_pts: gpd.GeoDataFrame,\n",
    "                    sample_col: str = 'none',\n",
    "                    ) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Select a suitable location for an activity based on the activity purpose and a specific zone\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    row : pandas.Series\n",
    "        A row from the activity_chains DataFrame\n",
    "    activities_pts : geopandas.GeoDataFrame\n",
    "        A GeoDataFrame containing the activities to sample from\n",
    "    sample_col : str, optional\n",
    "        The column to sample from, by default 'none'.Options are: \"floor_area\", \"none\"\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    activity_id : int\n",
    "        The id of the chosen activity\n",
    "    activity_geom : shapely.geometry\n",
    "        The geometry of the chosen activity\n",
    "\n",
    "    \"\"\"\n",
    "    destination_zone = row['dzone']\n",
    "\n",
    "    if destination_zone == 'NA':\n",
    "        # log the error\n",
    "        logging.info(f\"Destination zone is NA for row {row}\")\n",
    "        return pd.Series([np.nan, np.nan])\n",
    "\n",
    "    # filter to activities in the dsired zone\n",
    "    activities_in_zone = activities_pts[activities_pts['OA21CD'] == destination_zone]\n",
    "\n",
    "    if activities_in_zone.empty:\n",
    "        logging.info(f\"No activities in zone {destination_zone}\")\n",
    "        return pd.Series([np.nan, np.nan])\n",
    "\n",
    "\n",
    "    # filter all rows in activities_in_zone where  activities includes the specific activity type\n",
    "    activities_valid = activities_in_zone[activities_in_zone['activities'].apply(lambda x: row['education_type'] in x)]\n",
    "    # if no activities match the exact education type, relax the constraint to just \"education\"\n",
    "    if activities_valid.empty:\n",
    "        logging.info(f\"No activities in zone {destination_zone} with education type {row['education_type']},\\\n",
    "                      Returning activities with education type 'education'\")\n",
    "        activities_valid = activities_in_zone[activities_in_zone['activities'].apply(lambda x: 'education' in x)]\n",
    "        # if still no activities match the education type, return NA\n",
    "        if activities_valid.empty:\n",
    "            logging.info(f\"No activities in zone {destination_zone} with education type 'education'\")\n",
    "            return pd.Series([np.nan, np.nan])\n",
    "\n",
    "    if sample_col == \"floor_area\":\n",
    "        # sample an activity from activities_valid based on the floor_area column\n",
    "        if activities_valid[\"floor_area\"].sum() != 0:\n",
    "            activity = activities_valid.sample(1, weights=activities_valid['floor_area'])\n",
    "        else:\n",
    "            activity = activities_valid.sample(1)\n",
    "    else:\n",
    "        activity = activities_valid.sample(1)\n",
    "\n",
    "    return pd.Series([activity['id'].values[0], activity['geometry'].values[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_chains_ex = activity_chains_edu.copy()\n",
    "\n",
    "\n",
    "# apply the function to a row in activity_chains_ex\n",
    "activity_chains_ex[['activity_id', 'activity_geom']] = activity_chains_ex.apply(lambda row: select_activity(row, osm_data_gdf, \"floor_area\"), axis=1)\n",
    "activity_chains_ex.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each row in activity_chains_ex, turn the geometry into a linestring: Origin = location and destination = activity_geom\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "activity_chains_plot = activity_chains_ex.copy()\n",
    "# filter to only include rows where activity_geom is not NA\n",
    "activity_chains_plot = activity_chains_plot[activity_chains_plot['activity_geom'].notna()]\n",
    "activity_chains_plot['line_geometry'] = activity_chains_plot.apply(lambda row: LineString([row['location'], row['activity_geom']]), axis=1)\n",
    "# Set the geometry column to 'line_geometry'\n",
    "activity_chains_plot = activity_chains_plot.set_geometry('line_geometry')\n",
    "\n",
    "# add the original crs\n",
    "activity_chains_plot.crs = \"EPSG:4326\"\n",
    "\n",
    "# convert crs to metric\n",
    "activity_chains_plot = activity_chains_plot.to_crs(epsg=3857)\n",
    "# calculate the length of the line_geometry in meters\n",
    "activity_chains_plot['length'] = activity_chains_plot['line_geometry'].length\n",
    "\n",
    "activity_chains_plot.head(10)\n",
    "\n",
    "# convert crs back to 4326\n",
    "activity_chains_plot = activity_chains_plot.to_crs(epsg=4326)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def plot_activity_chains(activities: pd.DataFrame, activity_type: str, bin_size: int, boundaries: gpd.GeoDataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Plots activity chains for a given activity type, bin size and geographical boundaries.\n",
    "\n",
    "    Parameters:\n",
    "    activities: pd.DataFrame\n",
    "        A DataFrame containing the activities data. Geometry is a LineString.\n",
    "    activity_type: str\n",
    "        The type of activity to plot.\n",
    "    bin_size: int\n",
    "        The size of the bins for the histogram. (in meters)\n",
    "    boundaries: gpd.GeoDataFrame \n",
    "        A GeoDataFrame containing the geographical boundaries for the plot.\n",
    "\n",
    "    Returns:\n",
    "        None    \n",
    "    \"\"\"\n",
    "    activities_subset = activities[activities['education_type'] == activity_type]\n",
    "    # Calculate the number of bins based on the maximum value of 'length'\n",
    "    num_bins = math.ceil(activities_subset['length'].max() / bin_size)\n",
    "\n",
    "    # Calculate the bin edges\n",
    "    bins = np.arange(num_bins + 1) * bin_size\n",
    "\n",
    "    # Create a new column 'length_band' by cutting 'length' into distance bands\n",
    "    activities_subset['length_band'] = pd.cut(activities_subset['length'], bins, include_lowest=True)\n",
    "\n",
    "    # Get unique bands and sort them\n",
    "    bands = activities_subset['length_band'].unique()\n",
    "    bands = sorted(bands, key=lambda x: x.left)\n",
    "\n",
    "    # Calculate the total number of trips\n",
    "    total_trips = len(activities_subset)\n",
    "\n",
    "    # Calculate the number of rows and columns for the subplots\n",
    "    nrows = math.ceil(len(bands) / 3)\n",
    "    ncols = 3\n",
    "\n",
    "    # Create a grid of subplots\n",
    "    fig, axs = plt.subplots(nrows, ncols, figsize=(20, 6 * nrows))\n",
    "\n",
    "    # Flatten axs for easy iteration\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for ax, band in zip(axs, bands):\n",
    "        # Get the subset for this band\n",
    "        subset_band = activities_subset[activities_subset['length_band'] == band]\n",
    "\n",
    "        # Calculate the percentage of trips in this band\n",
    "        percentage = len(subset_band) / total_trips * 100\n",
    "\n",
    "        # Plot the boundaries\n",
    "        boundaries.plot(ax=ax, color='lightgrey')\n",
    "\n",
    "        # Plot the subset\n",
    "        subset_band.plot(ax=ax, markersize=1)\n",
    "\n",
    "        # Set the title\n",
    "        ax.set_title(f'{activity_type},\\ndistance band: {band},\\nNo. of trips: {len(subset_band)} ({percentage:.2f}%)')\n",
    "\n",
    "    # Remove any unused subplots\n",
    "    for i in range(len(bands), nrows*ncols):\n",
    "        fig.delaxes(axs[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activity_chains(activity_chains_plot, \"education_kg\", 5000, boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activity_chains(activity_chains_plot, \"education_school\", 5000, boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activity_chains(activity_chains_plot, \"education_university\", 5000, boundaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bar Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_types = activity_chains_plot['education_type'].unique()\n",
    "\n",
    "# Calculate the number of rows needed for the subplot grid\n",
    "nrows = int(np.ceil(len(education_types) / 2))\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=2, figsize=(20, 8*nrows))\n",
    "\n",
    "# Flatten the axes array to make it easier to iterate over\n",
    "axs = axs.flatten()\n",
    "\n",
    "for ax, education_type in zip(axs, education_types):\n",
    "    subset = activity_chains_plot[activity_chains_plot['education_type'] == education_type]\n",
    "    ax.hist(subset['length'], bins=30, edgecolor='black')\n",
    "    ax.set_title(f'Activity Chain Lengths for {education_type}')\n",
    "    ax.set_xlabel('Length')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# Remove any unused subplots\n",
    "for ax in axs[len(education_types):]:\n",
    "    ax.remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_chains_plot['length'] = activity_chains_plot['length'] / 1000\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Histogram of 'TripDisIncSW'\n",
    "axs[0].hist(activity_chains_plot['TripDisIncSW'], bins=15, edgecolor='black')\n",
    "axs[0].set_title('TripDisIncSW (NTS)')\n",
    "\n",
    "# Histogram of 'length'\n",
    "axs[1].hist(activity_chains_plot['length'], bins=15, edgecolor='black')\n",
    "axs[1].set_title('Actual Trip Length (After assigning to location)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic for assigning people to educational facilities\n",
    "\n",
    "    for each zone \n",
    "        identify individuals with dact = education\n",
    "        for each individual\n",
    "            get feasible zones (TripTotalTime (NTS) - buffer <= travel time to zone <= TripTotalTime (NTS) + buffer)       # Do we use travel time or distance?\n",
    "            if there are feasible zones\n",
    "                if individual_age <= 11\n",
    "                    assign individual to random school in feasible zones where type = primary \n",
    "                else if individual_age <= 16 and individual_age > 11\n",
    "                    assign individual to random school in feasible zones where type = secondary or technical\n",
    "                else if individual_age > 16 and individual_age <= 18\n",
    "                    assign individual to random school in feasible zones where type = college OR university\n",
    "                else\n",
    "                    assign individual to random school in feasible zones where type = college OR university OR technical\n",
    "            else\n",
    "                assign individual to zone with shortest travel time\n",
    "\n",
    "- if I have the total number of people enrolled in secondary, technical, college, and university, I can assign make sure that the number of people matched to each educational facility type matches the actual figures. I would use the total numbers and do sampling without replacement\n",
    "- I could assign to zones and then use pam to assign to a random facility\n",
    "\n",
    "\n",
    "\"All education-related trips from the household travel survey were first split into several groups depending first on the residence area type (see subsubsection 5.1.2) the agent lives in, secondly, on the agent’s gender, and, thirdly, on the age of the individual sample who made the trip (and thus on the category of education facility the individual visited: pre-school or elementary school for children aged 14 or less, high school or technical school for teenagers aged 14 to 18, university for people aged 18 to 30 and various places for agents aged 30 or more. For each of these groups, it was then possible to construct the histogram of the distances separating the education place to the home of the individual samples. Finally, a probability density function corresponding to each histogram was obtained.\" - A synthetic population for the greater São Paulo metropolitan region (Sallard et al 2020)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acbm-7iKwKWLy-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
