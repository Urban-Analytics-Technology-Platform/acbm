{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding activity chains to synthetic populations \n",
    "\n",
    "The purpose of this script is to match each individual in the synthetic population to a respondant from the [National Travel Survey (NTS)](https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=5340).\n",
    "\n",
    "### Methods\n",
    "\n",
    "We will try two methods\n",
    "\n",
    "1. categorical matching: joining on relevant socio-demographic variables\n",
    "2. statistical matching, as described in [An unconstrained statistical matching algorithm for combining individual and household level geo-specific census and survey data](https://doi.org/10.1016/j.compenvurbsys.2016.11.003)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "\n",
    "# from tqdm.notebook import trange\n",
    "from acbm.matching import match_categorical, match_individuals\n",
    "from acbm.preprocessing import (\n",
    "    count_per_group,\n",
    "    #nts_filter_by_region,\n",
    "    nts_filter_by_year,\n",
    "    num_adult_child_hh,\n",
    "    transform_by_group,\n",
    "    truncate_values,\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "def get_interim_path(file_name: str, path: str=\"../data/interim/matching/\") -> str:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    return f'{path}/{file_name}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load in the datasets  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful variables\n",
    "region = \"west-yorkshire\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>household</th>\n",
       "      <th>workplace</th>\n",
       "      <th>events</th>\n",
       "      <th>weekday_diaries</th>\n",
       "      <th>weekend_diaries</th>\n",
       "      <th>orig_pid</th>\n",
       "      <th>id_tus_hh</th>\n",
       "      <th>id_tus_p</th>\n",
       "      <th>pid_hs</th>\n",
       "      <th>msoa11cd</th>\n",
       "      <th>oa11cd</th>\n",
       "      <th>members</th>\n",
       "      <th>bmi</th>\n",
       "      <th>has_cardiovascular_disease</th>\n",
       "      <th>has_diabetes</th>\n",
       "      <th>has_high_blood_pressure</th>\n",
       "      <th>number_medications</th>\n",
       "      <th>self_assessed_health</th>\n",
       "      <th>life_satisfaction</th>\n",
       "      <th>sic1d2007</th>\n",
       "      <th>sic2d2007</th>\n",
       "      <th>soc2010</th>\n",
       "      <th>pwkstat</th>\n",
       "      <th>salary_yearly</th>\n",
       "      <th>salary_hourly</th>\n",
       "      <th>hid</th>\n",
       "      <th>nssec8</th>\n",
       "      <th>accommodation_type</th>\n",
       "      <th>communal_type</th>\n",
       "      <th>num_rooms</th>\n",
       "      <th>central_heat</th>\n",
       "      <th>tenure</th>\n",
       "      <th>num_cars</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_years</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>nssec8_household</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'concert_f': 1.2791347489984115e-31, 'concert...</td>\n",
       "      <td>[1583, 13161]</td>\n",
       "      <td>[1582, 13160]</td>\n",
       "      <td>E02002183_0001_001</td>\n",
       "      <td>11291218</td>\n",
       "      <td>1</td>\n",
       "      <td>2905399</td>\n",
       "      <td>E02002183</td>\n",
       "      <td>E00053954</td>\n",
       "      <td>[0]</td>\n",
       "      <td>24.879356</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>J</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E02002183_0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'concert_f': 9.743248151956307e-21, 'concert_...</td>\n",
       "      <td>[2900, 4948, 4972, 7424, 10284, 10586, 12199, ...</td>\n",
       "      <td>[2901, 4949, 4973, 7425, 10285, 10585, 12198, ...</td>\n",
       "      <td>E02002183_0002_001</td>\n",
       "      <td>17291219</td>\n",
       "      <td>1</td>\n",
       "      <td>2905308</td>\n",
       "      <td>E02002183</td>\n",
       "      <td>E00053953</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>27.491207</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1121.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E02002183_0002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'concert_f': 8.46716103992468e-16, 'concert_f...</td>\n",
       "      <td>[3010, 6389, 9448, 10184, 11598]</td>\n",
       "      <td>[3011, 6388, 9447, 10183, 11599]</td>\n",
       "      <td>E02002183_0002_002</td>\n",
       "      <td>17070713</td>\n",
       "      <td>2</td>\n",
       "      <td>2907681</td>\n",
       "      <td>E02002183</td>\n",
       "      <td>E00053953</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>17.310829</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>P</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2311.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E02002183_0002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>56126.0</td>\n",
       "      <td>{'concert_f': 1.8844366073608398, 'concert_fs'...</td>\n",
       "      <td>[366, 867, 2096, 3678, 5212, 5450, 8145, 9254,...</td>\n",
       "      <td>[365, 868, 2097, 3677, 5213, 5451, 8146, 9253,...</td>\n",
       "      <td>E02002183_0003_001</td>\n",
       "      <td>20310313</td>\n",
       "      <td>1</td>\n",
       "      <td>2902817</td>\n",
       "      <td>E02002183</td>\n",
       "      <td>E00053689</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>20.852091</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>C</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3422.0</td>\n",
       "      <td>1</td>\n",
       "      <td>32857.859375</td>\n",
       "      <td>14.360952</td>\n",
       "      <td>E02002183_0003</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'concert_f': 4.877435207366943, 'concert_fs':...</td>\n",
       "      <td>[1289, 12528, 12870]</td>\n",
       "      <td>[1288, 12529, 12871]</td>\n",
       "      <td>E02002183_0003_002</td>\n",
       "      <td>13010909</td>\n",
       "      <td>3</td>\n",
       "      <td>2900884</td>\n",
       "      <td>E02002183</td>\n",
       "      <td>E00053689</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>20.032526</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>J</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7214.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18162.451172</td>\n",
       "      <td>9.439944</td>\n",
       "      <td>E02002183_0003</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  household  workplace  \\\n",
       "0   0          0        NaN   \n",
       "1   1          1        NaN   \n",
       "2   2          1        NaN   \n",
       "3   3          2    56126.0   \n",
       "4   4          2        NaN   \n",
       "\n",
       "                                              events  \\\n",
       "0  {'concert_f': 1.2791347489984115e-31, 'concert...   \n",
       "1  {'concert_f': 9.743248151956307e-21, 'concert_...   \n",
       "2  {'concert_f': 8.46716103992468e-16, 'concert_f...   \n",
       "3  {'concert_f': 1.8844366073608398, 'concert_fs'...   \n",
       "4  {'concert_f': 4.877435207366943, 'concert_fs':...   \n",
       "\n",
       "                                     weekday_diaries  \\\n",
       "0                                      [1583, 13161]   \n",
       "1  [2900, 4948, 4972, 7424, 10284, 10586, 12199, ...   \n",
       "2                   [3010, 6389, 9448, 10184, 11598]   \n",
       "3  [366, 867, 2096, 3678, 5212, 5450, 8145, 9254,...   \n",
       "4                               [1289, 12528, 12870]   \n",
       "\n",
       "                                     weekend_diaries            orig_pid  \\\n",
       "0                                      [1582, 13160]  E02002183_0001_001   \n",
       "1  [2901, 4949, 4973, 7425, 10285, 10585, 12198, ...  E02002183_0002_001   \n",
       "2                   [3011, 6388, 9447, 10183, 11599]  E02002183_0002_002   \n",
       "3  [365, 868, 2097, 3677, 5213, 5451, 8146, 9253,...  E02002183_0003_001   \n",
       "4                               [1288, 12529, 12871]  E02002183_0003_002   \n",
       "\n",
       "   id_tus_hh  id_tus_p   pid_hs   msoa11cd     oa11cd members        bmi  \\\n",
       "0   11291218         1  2905399  E02002183  E00053954     [0]  24.879356   \n",
       "1   17291219         1  2905308  E02002183  E00053953  [1, 2]  27.491207   \n",
       "2   17070713         2  2907681  E02002183  E00053953  [1, 2]  17.310829   \n",
       "3   20310313         1  2902817  E02002183  E00053689  [3, 4]  20.852091   \n",
       "4   13010909         3  2900884  E02002183  E00053689  [3, 4]  20.032526   \n",
       "\n",
       "   has_cardiovascular_disease  has_diabetes  has_high_blood_pressure  \\\n",
       "0                       False         False                    False   \n",
       "1                       False         False                     True   \n",
       "2                       False          True                     True   \n",
       "3                       False         False                    False   \n",
       "4                       False         False                    False   \n",
       "\n",
       "   number_medications  self_assessed_health  life_satisfaction sic1d2007  \\\n",
       "0                 NaN                   3.0                2.0         J   \n",
       "1                 NaN                   3.0                NaN         C   \n",
       "2                 NaN                   2.0                4.0         P   \n",
       "3                 NaN                   2.0                1.0         C   \n",
       "4                 1.0                   2.0                3.0         J   \n",
       "\n",
       "   sic2d2007  soc2010  pwkstat  salary_yearly  salary_hourly             hid  \\\n",
       "0       58.0   1115.0        6            NaN            NaN  E02002183_0001   \n",
       "1       25.0   1121.0        6            NaN            NaN  E02002183_0002   \n",
       "2       85.0   2311.0        6            NaN            NaN  E02002183_0002   \n",
       "3       31.0   3422.0        1   32857.859375      14.360952  E02002183_0003   \n",
       "4       62.0   7214.0        1   18162.451172       9.439944  E02002183_0003   \n",
       "\n",
       "   nssec8  accommodation_type  communal_type  num_rooms  central_heat  tenure  \\\n",
       "0     1.0                 1.0            NaN        2.0          True     2.0   \n",
       "1     1.0                 3.0            NaN        6.0          True     2.0   \n",
       "2     1.0                 3.0            NaN        6.0          True     2.0   \n",
       "3     4.0                 3.0            NaN        6.0          True     2.0   \n",
       "4     4.0                 3.0            NaN        6.0          True     2.0   \n",
       "\n",
       "   num_cars  sex  age_years  ethnicity  nssec8_household  \n",
       "0         2    1         86          1               1.0  \n",
       "1         2    1         74          3               1.0  \n",
       "2         2    2         68          1               2.0  \n",
       "3         1    1         27          1               4.0  \n",
       "4         1    2         26          1               6.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the spc data (parquet format)\n",
    "spc = pd.read_parquet('../data/external/spc_output/' + region + '_people_hh.parquet')\n",
    "spc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns\n",
    "spc = spc[['id', 'household', 'pid_hs',\n",
    "       'msoa11cd', 'oa11cd', 'members', 'sic1d2007', 'sic2d2007',\n",
    "       'pwkstat', 'salary_yearly', 'salary_hourly', 'hid',\n",
    "       'accommodation_type', 'communal_type', 'num_rooms', 'central_heat',\n",
    "       'tenure', 'num_cars', 'sex', 'age_years', 'ethnicity', 'nssec8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary reduction of the dataset for quick analysis\n",
    "spc = spc.head(15000)\n",
    "#spc = spc.head(500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NTS\n",
    "\n",
    "The NTS is split up into multiple tables. We will load in the following tables:\n",
    "- individuals\n",
    "- households\n",
    "- trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_psu = \"../data/external/nts/UKDA-5340-tab/tab/psu_eul_2002-2022.tab\"\n",
    "psu = pd.read_csv(path_psu, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_individuals = \"../data/external/nts/UKDA-5340-tab/tab/individual_eul_2002-2022.tab\"\n",
    "nts_individuals = pd.read_csv(path_individuals,\n",
    "                              sep=\"\\t\",\n",
    "                              usecols = ['IndividualID',\n",
    "                                         'HouseholdID',\n",
    "                                          'PSUID',\n",
    "                                          'Age_B01ID',\n",
    "                                          'Age_B04ID',\n",
    "                                          'Sex_B01ID',\n",
    "                                          'OfPenAge_B01ID',\n",
    "                                          'HRPRelation_B01ID',\n",
    "                                          'EdAttn1_B01ID',\n",
    "                                          'EdAttn2_B01ID',\n",
    "                                          'EdAttn3_B01ID',\n",
    "                                          'OwnCycle_B01ID', # Owns a cycle\n",
    "                                          'DrivLic_B02ID', # type of driving license\n",
    "                                          'CarAccess_B01ID',\n",
    "                                          'IndIncome2002_B02ID',\n",
    "                                          'IndWkGOR_B02ID', # Region of usual place of work\n",
    "                                          'EcoStat_B02ID', # Working status of individual\n",
    "                                          'EcoStat_B03ID',\n",
    "                                          'NSSec_B03ID', # NSSEC high level breakdown\n",
    "                                          'SC_B01ID', # Social class of individual\n",
    "                                          'Stat_B01ID', # employee or self-employed\n",
    "                                          'WkMode_B01ID', # Usual means of travel to work\n",
    "                                          'WkHome_B01ID', # Work from home\n",
    "                                          'PossHom_B01ID', # Is it possible to work from home?\n",
    "                                          'OftHome_B01ID', # How often work from home\n",
    "                                          'TravSh_B01ID', # Usual mode from main food shopping trip\n",
    "                                          'SchDly_B01ID', # Daily school journey?\n",
    "                                          'SchTrav_B01ID', # Usual mode of travel to school\n",
    "                                          'SchAcc_B01ID', # IS school trip accompanied by an adult?\n",
    "                                          'FdShp_B01ID', # How do you usually carry ot main food shop (go to shop, online etc)\n",
    "                                          ]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_households = \"../data/external/nts/UKDA-5340-tab/tab/household_eul_2002-2022.tab\"\n",
    "nts_households = pd.read_csv(path_households,\n",
    "                             sep=\"\\t\",\n",
    "                             usecols = ['HouseholdID',\n",
    "                                        'PSUID',\n",
    "                                        'HHIncome2002_B02ID',\n",
    "                                        'AddressType_B01ID', # type of house\n",
    "                                        'Ten1_B02ID', # type of tenure\n",
    "                                        'HHoldNumAdults', # total no. of adults in household\n",
    "                                        'HHoldNumChildren', # total no. of children in household\n",
    "                                        'HHoldNumPeople', # total no. of people in household\n",
    "                                        'NumLicHolders', # total no. of driving license holders in household\n",
    "                                        'HHoldEmploy_B01ID', # number of employed in household\n",
    "                                        'NumBike', # no. of bikes\n",
    "                                        'NumCar', # no. of cars\n",
    "                                        'NumVanLorry', # no. of vans or lorries\n",
    "                                        'NumMCycle', # no. of motorcycles\n",
    "                                        'WalkBus_B01ID', # walk time from house to nearest bus stop\n",
    "                                        'Getbus_B01ID', # frequency of bus service\n",
    "                                        'WalkRail_B01ID', # walk time from house to nearest rail station\n",
    "                                        'JTimeHosp_B01ID', # journey time to nearest hospital\n",
    "                                        'DVShop_B01ID', # person no. for main food shooper in hh\n",
    "                                        'Settlement2011EW_B03ID', # ONS Urban/Rural: 2 categories\n",
    "                                        'Settlement2011EW_B04ID', # ONS Urban/Rural: 3 categories\n",
    "                                        'HHoldOAClass2011_B03ID', # Census 2011 OA Classification\n",
    "                                        'HRPWorkStat_B02ID', # HH ref person working status\n",
    "                                        'HRPSEGWorkStat_B01ID', #  HH ref person socio economic group for active workers\n",
    "                                        'W0', # Unweighted interview sample\n",
    "                                        'W1', # Unweighted diary sample\n",
    "                                        'W2', # Weighted diary sample\n",
    "                                        'W3', # Weighted interview sample\n",
    "                                        ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_trips = \"../data/external/nts/UKDA-5340-tab/tab/trip_eul_2002-2022.tab\"\n",
    "nts_trips = pd.read_csv(path_trips,\n",
    "                        sep=\"\\t\",\n",
    "                        usecols = ['TripID',\n",
    "                                   'DayID',\n",
    "                                   'IndividualID',\n",
    "                                   'HouseholdID',\n",
    "                                   'PSUID',\n",
    "                                   'PersNo',\n",
    "                                   'TravDay',\n",
    "                                   'JourSeq',\n",
    "                                   'ShortWalkTrip_B01ID',\n",
    "                                   'NumStages',\n",
    "                                   'MainMode_B03ID',\n",
    "                                   'MainMode_B04ID',\n",
    "                                   'TripPurpFrom_B01ID',\n",
    "                                   'TripPurpTo_B01ID',\n",
    "                                   'TripPurpose_B04ID',\n",
    "                                   'TripStart',\n",
    "                                   'TripEnd',\n",
    "                                   'TripTotalTime',\n",
    "                                   'TripTravTime',\n",
    "                                   'TripDisIncSW',\n",
    "                                   'TripDisExSW',\n",
    "                                   'TripOrigGOR_B02ID',\n",
    "                                   'TripDestGOR_B02ID',\n",
    "                                   'W5',\n",
    "                                   'W5xHH'\n",
    "                        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter by year\n",
    "\n",
    "We will filter the NTS data to only include data from specific years. We can choose only 1 year, or multiple years to increase our sample size and the likelihood of a match with the spc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2019, 2021, 2022]\n",
    "\n",
    "nts_individuals = nts_filter_by_year(nts_individuals, psu, years)\n",
    "nts_households = nts_filter_by_year(nts_households, psu, years)\n",
    "nts_trips = nts_filter_by_year(nts_trips, psu, years)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter by geography \n",
    "\n",
    "I will not do this for categorical matching, as it reduces the sample significantly, and leads to more spc households not being matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regions = ['Yorkshire and the Humber', 'North West']\n",
    "\n",
    "# nts_individuals = nts_filter_by_region(nts_individuals, psu, regions)\n",
    "# nts_households = nts_filter_by_region(nts_households, psu, regions)\n",
    "# nts_trips = nts_filter_by_region(nts_trips, psu, regions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionaries of key value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "guide to the dictionaries:\n",
    "\n",
    "_nts_hh: from NTS households table\n",
    "_nts_ind: from NTS individuals table\n",
    "_spc: from SPC\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# ---------- NTS\n",
    "\n",
    "# Create a dictionary for the HHIncome2002_B02ID column\n",
    "income_dict_nts_hh = {\n",
    "     '1': '0-25k',\n",
    "     '2': '25k-50k',\n",
    "     '3': '50k+',\n",
    "    '-8': 'NA',\n",
    "    # should be -10, but\n",
    "    # it could be a typo in household_eul_2002-2022_ukda_data_dictionary\n",
    "    '-1': 'DEAD'\n",
    "}\n",
    "\n",
    "# Create a dictionary for the HHoldEmploy_B01ID column\n",
    "# (PT: Part time, FT: Full time)\n",
    "employment_dict_nts_hh = {\n",
    "    '1': 'None',\n",
    "    '2': '0 FT, 1 PT',\n",
    "    '3': '1 FT, 0 PT',\n",
    "    '4': '0 FT, 2 PT',\n",
    "    '5': '1 FT, 1 PT',\n",
    "    '6': '2 FT, 0 PT',\n",
    "    '7': '1 FT, 2+ PT',\n",
    "    '8': '2 FT, 1+ PT',\n",
    "    '9': '0 FT, 3+ PT',\n",
    "    '10': '3+ FT, 0 PT',\n",
    "    '11': '3+ FT, 1+ PT',\n",
    "    '-8': 'NA',\n",
    "    '-10': 'DEAD'\n",
    "}\n",
    "\n",
    "# Create a dictionary for the Ten1_B02ID column\n",
    "tenure_dict_nts_hh = {\n",
    "    '1': 'Owns / buying',\n",
    "    '2': 'Rents',\n",
    "    '3': 'Other (including rent free)',\n",
    "    '-8': 'NA',\n",
    "    '-9': 'DNA',\n",
    "    '-10': 'DEAD'\n",
    "}\n",
    "\n",
    "\n",
    "# ---------- SPC\n",
    "\n",
    "\n",
    "# create a dictionary for the pwkstat column\n",
    "employment_dict_spc = {\n",
    "    '0': 'Not applicable (age < 16)',\n",
    "    '1': 'Employee FT',\n",
    "    '2': 'Employee PT',\n",
    "    '3': 'Employee unspecified',\n",
    "    '4': 'Self-employed',\n",
    "    '5': 'Unemployed',\n",
    "    '6': 'Retired',\n",
    "    '7': 'Homemaker/Maternal leave',\n",
    "    '8': 'Student',\n",
    "    '9': 'Long term sickness/disability',\n",
    "    '10': 'Other'\n",
    "}\n",
    "\n",
    "\n",
    "# Create a dictionary for the tenure column\n",
    "tenure_dict_spc = {\n",
    "    '1': 'Owned: Owned outright',\n",
    "    '2': 'Owned: Owned with a mortgage or loan or shared ownership',\n",
    "    '3': 'Rented or living rent free: Total',\n",
    "    '4': 'Rented: Social rented',\n",
    "    '5': 'Rented: Private rented or living rent free',\n",
    "    '-8': 'NA',\n",
    "    '-9': 'DNA',\n",
    "    '-10': 'DEAD'\n",
    "}\n",
    "\n",
    "\n",
    "# Combine the dictionaries into a dictionary of dictionaries\n",
    "\n",
    "dict_nts = {\n",
    "    'HHIncome2002_B02ID': income_dict_nts_hh,\n",
    "    'HHoldEmploy_B01ID': employment_dict_nts_hh,\n",
    "    'Ten1_B02ID': tenure_dict_nts_hh\n",
    "}\n",
    "\n",
    "dict_spc = {\n",
    "    'pwkstat': employment_dict_spc,\n",
    "    'tenure': tenure_dict_spc\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Decide on matching variables  \n",
    "\n",
    "We need to identify the socio-demographic characteristics that we will match on. The schema for the synthetic population can be found [here](https://github.com/alan-turing-institute/uatk-spc/blob/main/synthpop.proto). \n",
    "\n",
    "Matching between the SPC and the NTS will happen in two steps: \n",
    "\n",
    "1. Match at the household level\n",
    "2. Match individuals within the household\n",
    "\n",
    "### Household level matching \n",
    "\n",
    "| Variable           | Name (NTS)           | Name (SPC)      | Transformation (NTS) | Transformation (SPC) |\n",
    "| ------------------ | -------------------- | --------------- | -------------------- | -------------------- |\n",
    "| Household income   | `HHIncome2002_BO2ID` | `salary_yearly` | NA                   | Group by household ID and sum |\n",
    "| Number of adults   | `HHoldNumAdults`        | `age_years`     | NA                   | Group by household ID and count |\n",
    "| Number of children | `HHoldNumChildren`      | `age_years`     | NA                   | Group by household ID and count |\n",
    "| Employment status  | `HHoldEmploy_B01ID`  | `pwkstat`       | NA                   | a) match to NTS categories. b) group by household ID |\n",
    "| Car ownership      | `NumCar`             | `num_cars`      | SPC is capped at 2. We change all entries > 2 to 2 | NA  |\n",
    "\n",
    "Other columns to match in the future\n",
    "| Variable           | Name (NTS)           | Name (SPC)      | Transformation (NTS) | Transformation (SPC) |\n",
    "| ------------------ | -------------------- | --------------- | -------------------- | -------------------- |\n",
    "| Type of tenancy    | `Ten1_B02ID`         | `tenure`        | ?? | ?? |\n",
    "|  Urban-Rural classification of residence | `Settlement2011EW_B04ID`         | NA     | NA            | Spatial join between [layer](https://www.gov.uk/government/collections/rural-urban-classification) and SPC  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Edit SPC columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Household Income\n",
    "\n",
    "Edit the spc so that we have household income as well as individual income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add household income column for SPC\n",
    "spc_edited = transform_by_group(data = spc,\n",
    "                                group_col = 'household',\n",
    "                                transform_col = 'salary_yearly',\n",
    "                                new_col = 'salary_yearly_hh',\n",
    "                                transformation_type = 'sum')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check number of individuals and households with reported salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram for individuals and households (include NAs as 0)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "ax[0].hist(spc_edited['salary_yearly'].fillna(0), bins=30)\n",
    "ax[0].set_title('Salary yearly (Individuals)')\n",
    "ax[0].set_xlabel('Salary yearly')\n",
    "ax[0].set_ylabel('Frequency')\n",
    "ax[1].hist(spc_edited['salary_yearly_hh'].fillna(0), bins=30)\n",
    "ax[1].set_title('Salary yearly (Households)')\n",
    "ax[1].set_xlabel('Salary yearly')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# statistics\n",
    "\n",
    "# print the total number of rows in the spc. Add a message \"Values =\"\n",
    "print(\"Individuals in SPC =\", spc_edited.shape[0])\n",
    "# number of individuals without reported income\n",
    "print(\"Individuals without reported income =\", spc_edited['salary_yearly'].isna().sum())\n",
    "# % of individuals with reported income (salary_yearly not equal NA)\n",
    "print(\"% of individuals with reported income =\", round((spc_edited['salary_yearly'].count() / spc_edited.shape[0]) * 100, 1))\n",
    "print(\"Individuals with reported income: 0 =\", spc_edited[spc_edited['salary_yearly'] == 0].shape[0])\n",
    "\n",
    "\n",
    "# print the total number of households\n",
    "print(\"Households in SPC =\", spc_edited['household'].nunique())\n",
    "# number of households without reported income (salary yearly_hh = 0)\n",
    "print(\"Households without reported income =\", spc_edited[spc_edited['salary_yearly_hh'] == 0].shape[0])\n",
    "# # % of households with reported income (salary_yearly not equal NA)\n",
    "print(\"% of households with reported income =\", round((spc_edited[spc_edited['salary_yearly_hh'] == 0].shape[0] / spc_edited['household'].nunique()) * 100, 1))\n",
    "print(\"Households with reported income: 0 =\", spc_edited[spc_edited['salary_yearly_hh'] == 0].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Recode column so that it matches the reported NTS values (Use income_dict_nts_hh dictionary for reference)\n",
    "\n",
    "# Define the bins (first )\n",
    "bins = [0, 24999, 49999, np.inf]\n",
    "# Define the labels for the bins\n",
    "labels = [1, 2, 3]\n",
    "\n",
    "spc_edited = spc_edited.copy()\n",
    "\n",
    "spc_edited['salary_yearly_hh_cat'] = (pd.cut(spc_edited['salary_yearly_hh'], bins=bins, labels=labels, include_lowest=True)\n",
    "                                       .astype('str')\n",
    "                                       .astype('float'))\n",
    "\n",
    "\n",
    "# replace NA values with -8 (to be consistent with NTS)\n",
    "spc_edited['salary_yearly_hh_cat'] = spc_edited['salary_yearly_hh_cat'].fillna(-8)\n",
    "\n",
    "# Convert the column to int\n",
    "spc_edited['salary_yearly_hh_cat'] = spc_edited['salary_yearly_hh_cat'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare household income from the SPC and the NTS, we find that the SPC has many more households with no reported income (-8). This will create an issue when matching using household income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot showing spc_edited.salary_yearly_hh_cat and nts_households.HHIncome2002_B02ID side by side\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "ax[0].bar(spc_edited['salary_yearly_hh_cat'].value_counts().index, spc_edited['salary_yearly_hh_cat'].value_counts().values)\n",
    "ax[0].set_title('SPC')\n",
    "ax[0].set_xlabel('Income Bracket - Household level')\n",
    "ax[0].set_ylabel('No of Households')\n",
    "ax[1].bar(nts_households['HHIncome2002_B02ID'].value_counts().index, nts_households['HHIncome2002_B02ID'].value_counts().values)\n",
    "ax[1].set_title('NTS')\n",
    "ax[1].set_xlabel('Income Bracket - Household level')\n",
    "plt.show()\n",
    "\n",
    "# same as above but (%)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "ax[0].bar(spc_edited['salary_yearly_hh_cat'].value_counts(normalize=True).index, spc_edited['salary_yearly_hh_cat'].value_counts(normalize=True).values)\n",
    "ax[0].set_title('SPC')\n",
    "ax[0].set_xlabel('Income Bracket - Household level')\n",
    "ax[0].set_ylabel('Fraction of Households')\n",
    "ax[1].bar(nts_households['HHIncome2002_B02ID'].value_counts(normalize=True).index, nts_households['HHIncome2002_B02ID'].value_counts(normalize=True).values)\n",
    "ax[1].set_title('NTS')\n",
    "ax[1].set_xlabel('Income Bracket - Household level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the % of households in each income bracket for the nts\n",
    "nts_households['HHIncome2002_B02ID'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Household Composition (No. of Adults / Children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of adults and children in the household\n",
    "\n",
    "spc_edited = num_adult_child_hh(data = spc_edited,\n",
    "                                group_col = 'household',\n",
    "                                age_col = 'age_years')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Employment Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employment status\n",
    "\n",
    "# check the colums values from our dictionary\n",
    "dict_spc['pwkstat'], dict_nts['HHoldEmploy_B01ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NTS only reports the number of Full time and Part time employees for each household. For the SPC we also need to get the number of full time and part time workers for each household.\n",
    "\n",
    "Step 1: Create a column for Full time and a column for Part time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will only use '1' and '2' for the employment status\n",
    "\n",
    "counts_df = count_per_group(df = spc_edited,\n",
    "                            group_col = 'household',\n",
    "                            count_col = 'pwkstat',\n",
    "                            values=[1, 2],\n",
    "                            value_names=['pwkstat_FT_hh','pwkstat_PT_hh'])\n",
    "\n",
    "counts_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a column that matches the NTS categories (m FT, n PT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to match the SPC values to the NTS\n",
    "dict_nts['HHoldEmploy_B01ID']\n",
    "'''\n",
    "{\n",
    "    '1': 'None',\n",
    "    '2': '0 FT, 1 PT',\n",
    "    '3': '1 FT, 0 PT',\n",
    "    '4': '0 FT, 2 PT',\n",
    "    '5': '1 FT, 1 PT',\n",
    "    '6': '2 FT, 0 PT',\n",
    "    '7': '1 FT, 2+ PT',\n",
    "    '8': '2 FT, 1+ PT',\n",
    "    '9': '0 FT, 3+ PT',\n",
    "    '10': '3+ FT, 0 PT',\n",
    "    '11': '3+ FT, 1+ PT',\n",
    "    '-8': 'NA',\n",
    "    '-10': 'DEAD'}\n",
    " '''\n",
    "\n",
    "# 1) Match each row to the NTS\n",
    "\n",
    "# Define the conditions and outputs.\n",
    "# We are using the keys in dict_nts['HHoldEmploy_B01ID'] as reference\n",
    "conditions = [\n",
    "    (counts_df['pwkstat_FT_hh'] == 0) & (counts_df['pwkstat_PT_hh'] == 0),\n",
    "    (counts_df['pwkstat_FT_hh'] == 0) & (counts_df['pwkstat_PT_hh'] == 1),\n",
    "    (counts_df['pwkstat_FT_hh'] == 1) & (counts_df['pwkstat_PT_hh'] == 0),\n",
    "    (counts_df['pwkstat_FT_hh'] == 0) & (counts_df['pwkstat_PT_hh'] == 2),\n",
    "    (counts_df['pwkstat_FT_hh'] == 1) & (counts_df['pwkstat_PT_hh'] == 1),\n",
    "    (counts_df['pwkstat_FT_hh'] == 2) & (counts_df['pwkstat_PT_hh'] == 0),\n",
    "    (counts_df['pwkstat_FT_hh'] == 1) & (counts_df['pwkstat_PT_hh'] >= 2),\n",
    "    (counts_df['pwkstat_FT_hh'] == 2) & (counts_df['pwkstat_PT_hh'] >= 1),\n",
    "    (counts_df['pwkstat_FT_hh'] == 0) & (counts_df['pwkstat_PT_hh'] >= 3),\n",
    "    (counts_df['pwkstat_FT_hh'] >= 3) & (counts_df['pwkstat_PT_hh'] == 0),\n",
    "    (counts_df['pwkstat_FT_hh'] >= 3) & (counts_df['pwkstat_PT_hh'] >= 1)\n",
    "]\n",
    "\n",
    "# Define the corresponding outputs based on dict_nts['HHoldEmploy_B01ID]\n",
    "outputs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "\n",
    "# Create a new column using np.select\n",
    "counts_df['pwkstat_NTS_match'] = np.select(conditions,\n",
    "                                           outputs,\n",
    "                                           default= -8)\n",
    "\n",
    "\n",
    "\n",
    "# 2) merge back onto the spc\n",
    "spc_edited = spc_edited.merge(counts_df, left_on='household', right_index=True)\n",
    "\n",
    "# check the output\n",
    "spc_edited[['household', 'pwkstat', 'pwkstat_FT_hh', 'pwkstat_PT_hh', 'pwkstat_NTS_match']].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot of counts_df['pwkstat_NTS_match'] and nts_households['HHoldEmploy_B01ID']\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].bar(counts_df['pwkstat_NTS_match'].value_counts().index, counts_df['pwkstat_NTS_match'].value_counts().values)\n",
    "ax[0].set_title('SPC')\n",
    "ax[0].set_xlabel('Employment status - Household level')\n",
    "ax[0].set_ylabel('Frequency')\n",
    "ax[1].bar(nts_households['HHoldEmploy_B01ID'].value_counts().index, nts_households['HHoldEmploy_B01ID'].value_counts().values)\n",
    "ax[1].set_title('NTS')\n",
    "ax[1].set_xlabel('Employment status - Household level')\n",
    "plt.show()\n",
    "\n",
    "# same as above but percentages\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].bar(counts_df['pwkstat_NTS_match'].value_counts().index, counts_df['pwkstat_NTS_match'].value_counts(normalize=True).values)\n",
    "ax[0].set_title('SPC')\n",
    "ax[0].set_xlabel('Employment status - Household level')\n",
    "ax[0].set_ylabel('Frequency (normalized)')\n",
    "ax[1].bar(nts_households['HHoldEmploy_B01ID'].value_counts().index, nts_households['HHoldEmploy_B01ID'].value_counts(normalize=True).values)\n",
    "ax[1].set_title('NTS')\n",
    "ax[1].set_xlabel('Employment status - Household level')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Urban Rural Classification\n",
    "\n",
    "We use the 2011 rural urban classification to match the SPC to the NTS. The NTS has 2 columns that we can use to match to the SPC: `Settlement2011EW_B03ID` and `Settlement2011EW_B04ID`. The `Settlement2011EW_B03ID` column is more general (urban / rural only), while the `Settlement2011EW_B04ID` column is more specific. We stick to the more general column for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the rural urban classification data\n",
    "rural_urban = pd.read_csv('../data/external/census_2011_rural_urban.csv', sep=',')\n",
    "\n",
    "# merge the rural_urban data with the spc\n",
    "spc_edited = spc_edited.merge(rural_urban[['OA11CD', 'RUC11', 'RUC11CD']], left_on='oa11cd', right_on='OA11CD')\n",
    "spc_edited.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary from the NTS `Settlement2011EW_B03ID` column\n",
    "Settlement2011EW_B03ID_nts_hh = {\n",
    "    '1': 'Urban',\n",
    "    '2': 'Rural',\n",
    "    '3': 'Scotland',\n",
    "    '-8': 'NA',\n",
    "    '-10': 'DEAD'\n",
    "}\n",
    "\n",
    "Settlement2011EW_B04ID_nts_hh = {\n",
    "    '1': 'Urban Conurbation',\n",
    "    '2': 'Urban City and Town',\n",
    "    '3': 'Rural Town and Fringe',\n",
    "    '4': 'Rural Village, Hamlet and Isolated Dwellings',\n",
    "    '5': 'Scotland',\n",
    "    '-8': 'NA',\n",
    "    '-10': 'DEAD'\n",
    "}\n",
    "\n",
    "\n",
    "census_2011_to_nts_B03ID = {\n",
    "    'Urban major conurbation': 'Urban',\n",
    "    'Urban minor conurbation': 'Urban',\n",
    "    'Urban city and town': 'Urban',\n",
    "    'Urban city and town in a sparse setting': 'Urban',\n",
    "    'Rural town and fringe': 'Rural',\n",
    "    'Rural town and fringe in a sparse setting': 'Rural',\n",
    "    'Rural village': 'Rural',\n",
    "    'Rural village in a sparse setting': 'Rural',\n",
    "    'Rural hamlets and isolated dwellings': 'Rural',\n",
    "    'Rural hamlets and isolated dwellings in a sparse setting': 'Rural'\n",
    "}\n",
    "\n",
    "census_2011_to_nts_B04ID = {\n",
    "    'Urban major conurbation': 'Urban Conurbation',\n",
    "    'Urban minor conurbation': 'Urban Conurbation',\n",
    "    'Urban city and town': 'Urban City and Town',\n",
    "    'Urban city and town in a sparse setting': 'Urban City and Town',\n",
    "    'Rural town and fringe': 'Rural Town and Fringe',\n",
    "    'Rural town and fringe in a sparse setting': 'Rural Town and Fringe',\n",
    "    'Rural village': 'Rural Village, Hamlet and Isolated Dwellings',\n",
    "    'Rural village in a sparse setting': 'Rural Village, Hamlet and Isolated Dwellings',\n",
    "    'Rural hamlets and isolated dwellings': 'Rural Village, Hamlet and Isolated Dwellings',\n",
    "    'Rural hamlets and isolated dwellings in a sparse setting': 'Rural Village, Hamlet and Isolated Dwellings'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the nts Settlement2011EW_B03ID and Settlement2011EW_B04ID columns to the spc\n",
    "spc_edited['Settlement2011EW_B03ID_spc'] = spc_edited['RUC11'].map(census_2011_to_nts_B03ID)\n",
    "spc_edited['Settlement2011EW_B04ID_spc'] = spc_edited['RUC11'].map(census_2011_to_nts_B04ID)\n",
    "spc_edited.head()\n",
    "\n",
    "# add the keys from nts_Settlement2011EW_B03ID and nts_Settlement2011EW_B04ID to the spc based on above mappings\n",
    "\n",
    "# reverse the dictionaries\n",
    "Settlement2011EW_B03ID_nts_rev = {v: k for k, v in Settlement2011EW_B03ID_nts_hh.items()}\n",
    "# map the values\n",
    "spc_edited['Settlement2011EW_B03ID_spc_CD'] = spc_edited['Settlement2011EW_B03ID_spc'].map(Settlement2011EW_B03ID_nts_rev).astype('int')\n",
    "\n",
    "Settlement2011EW_B04ID_nts_rev = {v: k for k, v in Settlement2011EW_B04ID_nts_hh.items()}\n",
    "spc_edited['Settlement2011EW_B04ID_spc_CD'] = spc_edited['Settlement2011EW_B04ID_spc'].map(Settlement2011EW_B04ID_nts_rev).astype('int')\n",
    "spc_edited.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Edit NTS columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of people of pension age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts_pensioners = count_per_group(df = nts_individuals,\n",
    "                                 group_col='HouseholdID',\n",
    "                                 count_col='OfPenAge_B01ID',\n",
    "                                 values=[1],\n",
    "                                 value_names=['num_pension_age_nts'])\n",
    "\n",
    "nts_pensioners.head()\n",
    "\n",
    "# join onto the nts household df\n",
    "nts_households = nts_households.merge(nts_pensioners, left_on='HouseholdID', right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of cars\n",
    "\n",
    "- `SPC.num_cars` only has values [0, 1, 2]. 2 is for all households with 2 or more cars\n",
    "- `NTS.NumCar` is more detailed. It has the actual value of the number of cars. We will cap this at 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a new column in NTS\n",
    "nts_households.loc[:, 'NumCar_SPC_match'] = nts_households['NumCar'].apply(truncate_values, upper = 2)\n",
    "\n",
    "nts_households[['NumCar', 'NumCar_SPC_match']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type of tenancy\n",
    "\n",
    "Breakdown between NTS and SPC is different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_nts['Ten1_B02ID'], dict_spc['tenure']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionaries to map tenure onto the spc and nts dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary showing how we want the final columns to look like\n",
    "tenure_dict_nts_spc = {\n",
    "    1: 'Owned',\n",
    "    2: 'Rented or rent free',\n",
    "    -8: 'NA',\n",
    "    -9: 'DNA',\n",
    "    -10: 'DEAD'\n",
    "}\n",
    "\n",
    "# Matching NTS to tenure_dict_nts_spc\n",
    "\n",
    "# Create a new dictionary for matching\n",
    "matching_dict_nts_tenure = {\n",
    "    1: 1,\n",
    "    2: 2,\n",
    "    3: 2\n",
    "}\n",
    "\n",
    "matching_dict_spc_tenure = {\n",
    "    1: 1, #'Owned: Owned outright' : 'Owned'\n",
    "    2: 1, #'Owned: Owned with a mortgage or loan or shared ownership', : 'Owned'\n",
    "    3: 2, #'Rented or living rent free: Total', : 'Rented or rent free'\n",
    "    4: 2, #'Rented: Social rented', : 'Rented or rent free'\n",
    "    5: 2, #'Rented: Private rented or living rent free', : 'Rented or rent free'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map dictionaries to create comparable columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column in nts_households\n",
    "nts_households['tenure_nts_for_matching'] = (nts_households['Ten1_B02ID']\n",
    "                                                    .map(matching_dict_nts_tenure) # map the values to the new dictionary\n",
    "                                                    .fillna(nts_households['Ten1_B02ID'])) # fill the NaNs with the original values\n",
    "\n",
    "# Create a new column in spc\n",
    "spc_edited['tenure_spc_for_matching'] = (spc_edited['tenure']\n",
    "                                        .map(matching_dict_spc_tenure) # map the values to the new dictionary\n",
    "                                        .fillna(spc_edited['tenure'])) # fill the NaNs with the original values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Matching at Household Level\n",
    "\n",
    "Now that we've prepared all the columns, we can start matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Categorical matching\n",
    "\n",
    "We will match on (a subset of) the following columns:\n",
    "\n",
    "| Matching variable | NTS column | SPC column |\n",
    "| ------------------| ---------- | ---------- |\n",
    "| Household income  | `HHIncome2002_BO2ID` | `salary_yearly_hh_cat` |\n",
    "| Number of adults  | `HHoldNumAdults` | `num_adults` |\n",
    "| Number of children | `HHoldNumChildren` | `num_children` |\n",
    "| Employment status | `HHoldEmploy_B01ID` | `pwkstat_NTS_match` |\n",
    "| Car ownership | `NumCar_SPC_match` | `num_cars` |\n",
    "| Type of tenancy | `tenure_nts_for_matching` | `tenure_spc_for_matching` |\n",
    "| Rural/Urban Classification | `Settlement2011EW_B03ID` | `Settlement2011EW_B03ID_spc_CD` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare SPC df for matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select multiple columns\n",
    "spc_matching = spc_edited[[\n",
    "    'hid',\n",
    "    'salary_yearly_hh_cat', 'num_adults',\n",
    "    'num_children', 'num_pension_age', 'pwkstat_NTS_match',\n",
    "    'num_cars', 'tenure_spc_for_matching',\n",
    "    'Settlement2011EW_B03ID_spc_CD', 'Settlement2011EW_B04ID_spc_CD']]\n",
    "\n",
    "# edit the df so that we have one row per hid\n",
    "spc_matching = spc_matching.drop_duplicates(subset='hid')\n",
    "\n",
    "spc_matching.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare NTS df for matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts_matching = nts_households[[\n",
    "    'HouseholdID','HHIncome2002_B02ID',\n",
    "    'HHoldNumAdults', 'HHoldNumChildren', 'num_pension_age_nts',\n",
    "    'HHoldEmploy_B01ID', 'NumCar_SPC_match',\n",
    "    'tenure_nts_for_matching',\n",
    "    'Settlement2011EW_B03ID', 'Settlement2011EW_B04ID']]\n",
    "\n",
    "nts_matching.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary of matching columns. We extract column names from this dictioary when matching on a subset of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_names (keys) for the dictionary\n",
    "matching_ids = ['household_id', 'yearly_income', 'number_adults', 'number_children', 'num_pension_age',\n",
    "                'employment_status', 'number_cars', 'tenure_status', 'rural_urban_2_categories', 'rural_urban_4_categories']\n",
    "\n",
    "# i want the value to be a list with spc_matching and nts_matching\n",
    "matching_dfs_dict = {column_name: [spc_value, nts_value] for column_name, spc_value, nts_value in zip(matching_ids, spc_matching, nts_matching)}\n",
    "matching_dfs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Match on a subset of columns (exclude salary, tenure, and employment status)\n",
    "\n",
    "To decide on the subset of columns to match on, we explore the results from different combinations. This is shown in a separate notebook: `2.1_sandbox-match_households.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns for matching\n",
    "keys = ['number_adults', 'number_children', 'num_pension_age', 'number_cars', 'rural_urban_2_categories']\n",
    "# extract equivalent column names from dictionary\n",
    "spc_cols = [matching_dfs_dict[key][0] for key in keys]\n",
    "nts_cols = [matching_dfs_dict[key][1] for key in keys]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_hh_level = match_categorical(\n",
    "    df_pop = spc_matching,\n",
    "    df_pop_cols = spc_cols,\n",
    "    df_pop_id = 'hid',\n",
    "    df_sample = nts_matching,\n",
    "    df_sample_cols = nts_cols,\n",
    "    df_sample_id = 'HouseholdID',\n",
    "    chunk_size = 50000,\n",
    "    show_progress = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot number of matches for each SPC household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the counts of each key\n",
    "counts = [len(v) for v in matches_hh_level.values()]\n",
    "\n",
    "# Create the histogram\n",
    "plt.hist(counts, bins='auto')  # 'auto' automatically determines the number of bins\n",
    "\n",
    "plt.title('Categorical (Exact) Matching - Household Level')\n",
    "plt.xlabel('No. of Households in SPC')\n",
    "plt.ylabel('No. of matching households in NTS')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of unmatched households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. of keys where value is na\n",
    "na_count = sum([1 for v in matches_hh_level.values() if pd.isna(v).all()])\n",
    "\n",
    "\n",
    "print(na_count, \"households in the SPC had no match\")\n",
    "print(round((na_count / len(matches_hh_level)) * 100, 1), \"% of households in the SPC had no match\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the 6th key, value in the matches_hh_level dictionary\n",
    "print(list(matches_hh_level.items())[90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add matches_hh_level as a column in spc_edited\n",
    "spc_edited['nts_hh_id'] = spc_edited['hid'].map(matches_hh_level)\n",
    "\n",
    "spc_edited.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Sampling from matched households\n",
    "\n",
    "In categorical matching, many households in the SPC are matched to more than 1 household in the NTS. Which household to choose? We do random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each key in the dictionary, sample 1 of the values associated with it and store it in a new dictionary\n",
    "\n",
    "'''\n",
    "- iterate over each key-value pair in the matches_hh_result dictionary.\n",
    "- For each key-value pair, use np.random.choice(value) to randomly select\n",
    "one item from the list of values associated with the current key.\n",
    "- create a new dictionary hid_to_HouseholdID_sample where each key from the\n",
    "original dictionary is associated with one randomly selected value from the\n",
    "original list of values.\n",
    "\n",
    "'''\n",
    "matches_hh_level_sample = {key: np.random.choice(value) for key, value in matches_hh_level.items()}\n",
    "\n",
    "# remove items in list where value is nan\n",
    "matches_hh_level_sample = {key: value for key, value in matches_hh_level_sample.items() if not pd.isna(value)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(matches_hh_level_sample.items())[568])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple matches in case we want to try stochastic runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same logic as cell above, but repeat it multiple times and store each result as a separate dictionary in a list\n",
    "matches_hh_level_sample_list = [{key: np.random.choice(value) for key, value in matches_hh_level.items()} for i in range(100)]\n",
    "\n",
    "#matches_hh_level_sample_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample\n",
    "with open(get_interim_path(\"matches_hh_level_categorical_random_sample.pkl\"), 'wb') as f:\n",
    "    pkl.dump(matches_hh_level_sample, f)\n",
    "\n",
    "# multiple random samples\n",
    "with open(get_interim_path('matches_hh_level_categorical_random_sample_multiple.pkl'), 'wb') as f:\n",
    "    pkl.dump(matches_hh_level_sample_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same at the df level. Add nts_hh_id_sample column to the spc df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for each hid in spc_edited, sample a value from the nts_hh_id col.\n",
    "# spc_edited['nts_hh_id_sample'] = spc_edited['nts_hh_id'].apply(lambda x: np.random.choice(x) if x is not np.nan else np.nan)\n",
    "# # All rows with the same 'hid' should have the same value for 'nts_hh_id_sample'. Group by hid and assign the first value to all rows in the group\n",
    "# spc_edited['nts_hh_id_sample'] = spc_edited.groupby('hid')['nts_hh_id_sample'].transform('first')\n",
    "\n",
    "# spc_edited.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Matching at Individual Level\n",
    "\n",
    "1) Prepare columns for matching - they should all be numerical\n",
    "    a) age_years in the SPC -> Convert from actual age to age brackets from the dictionary\n",
    "2) Filter to specific household\n",
    "3) Nearest neighbor merge without replacement (edit while function below)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts_individuals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an 'age' column in the SPC that matches the NTS categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary for reference on how the labels for \"Age_B04ID\" match the actual age brackets\n",
    "\n",
    "# dict_nts_ind_age = {-10: 'DEAD',\n",
    "#                     -8: 'NA',\n",
    "#                     1: '0-4',\n",
    "#                     2: '5-10',\n",
    "#                     3: '11-16',\n",
    "#                     4: '17-20',\n",
    "#                     5: '21-29',\n",
    "#                     6: '30-39',\n",
    "#                     7: '40-49',\n",
    "#                     8: '50-59',\n",
    "#                     9: '60+'\n",
    "#                     }\n",
    "\n",
    "\n",
    "# Define the bins and labels based on dict_nts_ind_age\n",
    "bins = [0, 4, 10, 16, 20, 29, 39, 49, 59, np.inf]\n",
    "labels = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# Create a new column in spc_edited that maps the age_years to the keys of dict_nts_ind_age\n",
    "spc_edited['age_group'] = (pd.cut(spc_edited['age_years'], bins=bins, labels=labels)\n",
    "                     .astype('int')\n",
    "                     .fillna(-8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename nts columns in preparation for matching\n",
    "\n",
    "nts_individuals.rename(columns={'Age_B04ID': 'age_group', 'Sex_B01ID': 'sex'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSM matching using internal match_individuals function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_ind = match_individuals(\n",
    "    df1 = spc_edited,\n",
    "    df2 = nts_individuals,\n",
    "    matching_columns = ['age_group', 'sex'],\n",
    "    df1_id = 'hid',\n",
    "    df2_id = 'HouseholdID',\n",
    "    matches_hh = matches_hh_level_sample,\n",
    "    show_progress = False)\n",
    "\n",
    "#matches_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Output the first n items of the dictionary\n",
    "dict(itertools.islice(matches_ind.items(), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add matches_ind values to spc_edited using map\n",
    "spc_edited['nts_ind_id'] = spc_edited.index.map(matches_ind)\n",
    "\n",
    "# add the nts_individuals.IndividualID to spc_edit. The current nts_ind_id is the row index of nts_individuals\n",
    "spc_edited['nts_ind_id'] = spc_edited['nts_ind_id'].map(nts_individuals['IndividualID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spc_edited.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that matching is working as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ids = [99, 100, 101, 102]\n",
    "ids = [109, 110, 111, 112, 113, 114]\n",
    "\n",
    "\n",
    "spc_rows = []\n",
    "nts_rows = []\n",
    "\n",
    "for id in ids:\n",
    "    # get spc and nts values for position id\n",
    "    spc_ind = list(matches_ind.keys())[id]\n",
    "    nts_ind = matches_ind[list(matches_ind.keys())[id]]\n",
    "\n",
    "    # get rows from spc and nts dfs that match spc_ind and nts_ind\n",
    "    spc_row = spc_edited.loc[spc_ind]\n",
    "    nts_row = nts_individuals.loc[nts_ind]\n",
    "\n",
    "    # convert to df and append\n",
    "    spc_rows.append(spc_row.to_frame().transpose())\n",
    "    nts_rows.append(nts_row.to_frame().transpose())\n",
    "# convert individual dfs to one df\n",
    "spc_rows_df = pd.concat(spc_rows)\n",
    "nts_rows_df = pd.concat(nts_rows)\n",
    "\n",
    "\n",
    "spc_rows_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "display(spc_rows_df[['id', 'household', 'pwkstat', 'salary_yearly', 'salary_hourly', 'hid',\n",
    "       'tenure', 'num_cars', 'sex', 'age_years','age_group', 'nssec8', 'salary_yearly_hh',\n",
    "       'salary_yearly_hh_cat', 'is_adult','is_child', 'is_pension_age','pwkstat_FT_hh', 'pwkstat_PT_hh',\n",
    "       'pwkstat_NTS_match', 'Settlement2011EW_B03ID_spc',\n",
    "       'Settlement2011EW_B04ID_spc', 'Settlement2011EW_B03ID_spc_CD', 'Settlement2011EW_B04ID_spc_CD']])\n",
    "\n",
    "display(nts_rows_df[['IndividualID', 'HouseholdID', 'Age_B01ID', 'age_group', 'sex','OfPenAge_B01ID', 'IndIncome2002_B02ID']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match on multiple samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In household level matching, some households in the SPC are matched to multiple households in the NTS. To have 1:1 match between the SPC and NTS, we randomly sample from the list of matches\n",
    "\n",
    "The random sample produces different results each time. In `matches_hh_level_sample_list` we did many iterations of random sampling to produce multiple results of household matching, and saved the output in a list of dictionaries. \n",
    "\n",
    "Here, we iterate over the list and do individual matching for each item. The output is a list of n dictionaries, each of which could be used as a synthetic population matched to the NTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over all items in the matches_hh_level_sample_list and apply the match_individuals function to each\n",
    "\n",
    "matches_list_of_dict = []\n",
    "for i in trange(len(matches_hh_level_sample_list)):\n",
    "    # apply match_individuals function to each item in the list\n",
    "    matches_ind = match_individuals(\n",
    "        df1 = spc_edited,\n",
    "        df2 = nts_individuals,\n",
    "        matching_columns = ['age_group', 'sex'],\n",
    "        df1_id = 'hid',\n",
    "        df2_id = 'HouseholdID',\n",
    "        matches_hh = matches_hh_level_sample_list[i],\n",
    "        show_progress= False)\n",
    "\n",
    "    matches_list_of_dict.append(matches_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results of individual matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample\n",
    "with open(get_interim_path(\"matches_ind_level_categorical_random_sample.pkl\"), 'wb') as f:\n",
    "    pkl.dump(matches_ind, f)\n",
    "\n",
    "# multiple random samples\n",
    "with open(get_interim_path('matches_ind_level_categorical_random_sample_multiple.pkl'), 'wb') as f:\n",
    "    pkl.dump(matches_list_of_dict, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add trip data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts_trips.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns and map actual modes and trip purposes to the trip table. \n",
    "\n",
    "Code taken from: https://github.com/arup-group/pam/blob/main/examples/07_travel_survey_to_matsim.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts_trips = nts_trips.rename(\n",
    "    columns={  # rename data\n",
    "        \"JourSeq\": \"seq\",\n",
    "        \"TripOrigGOR_B02ID\": \"ozone\",\n",
    "        \"TripDestGOR_B02ID\": \"dzone\",\n",
    "        \"TripPurpFrom_B01ID\": \"oact\",\n",
    "        \"TripPurpTo_B01ID\": \"dact\",\n",
    "        \"MainMode_B04ID\": \"mode\",\n",
    "        \"TripStart\": \"tst\",\n",
    "        \"TripEnd\": \"tet\",\n",
    "    }\n",
    ")\n",
    "\n",
    "nts_trips.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_mapping = {\n",
    "    1: \"walk\",\n",
    "    2: \"bike\",\n",
    "    3: \"car\",  #'Car/van driver'\n",
    "    4: \"car\",  #'Car/van driver'\n",
    "    5: \"motorcycle\",  #'Motorcycle',\n",
    "    6: \"car\",  #'Other private transport',\n",
    "    7: \"pt\",  # Bus in London',\n",
    "    8: \"pt\",  #'Other local bus',\n",
    "    9: \"pt\",  #'Non-local bus',\n",
    "    10: \"pt\",  #'London Underground',\n",
    "    11: \"pt\",  #'Surface Rail',\n",
    "    12: \"car\",  #'Taxi/minicab',\n",
    "    13: \"pt\",  #'Other public transport',\n",
    "    -10: \"DEAD\",\n",
    "    -8: \"NA\",\n",
    "}\n",
    "\n",
    "purp_mapping = {\n",
    "    1: \"work\",\n",
    "    2: \"work\",  #'In course of work',\n",
    "    3: \"education\",\n",
    "    4: \"shop\",  #'Food shopping',\n",
    "    5: \"shop\",  #'Non food shopping',\n",
    "    6: \"medical\",  #'Personal business medical',\n",
    "    7: \"other\",  #'Personal business eat/drink',\n",
    "    8: \"other\",  #'Personal business other',\n",
    "    9: \"other\",  #'Eat/drink with friends',\n",
    "    10: \"visit\",  #'Visit friends',\n",
    "    11: \"other\",  #'Other social',\n",
    "    12: \"other\",  #'Entertain/ public activity',\n",
    "    13: \"other\",  #'Sport: participate',\n",
    "    14: \"home\",  #'Holiday: base',\n",
    "    15: \"other\",  #'Day trip/just walk',\n",
    "    16: \"other\",  #'Other non-escort',\n",
    "    17: \"escort\",  #'Escort home',\n",
    "    18: \"escort\",  #'Escort work',\n",
    "    19: \"escort\",  #'Escort in course of work',\n",
    "    20: \"escort\",  #'Escort education',\n",
    "    21: \"escort\",  #'Escort shopping/personal business',\n",
    "    22: \"escort\",  #'Other escort',\n",
    "    23: \"home\",  #'Home',\n",
    "    -10: \"DEAD\",\n",
    "    -8: \"NA\",\n",
    "}\n",
    "\n",
    "\n",
    "nts_trips[\"mode\"] = nts_trips[\"mode\"].map(mode_mapping)\n",
    "\n",
    "nts_trips[\"oact\"] = nts_trips[\"oact\"].map(purp_mapping)\n",
    "\n",
    "nts_trips[\"dact\"] = nts_trips[\"dact\"].map(purp_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts_trips.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an independant copy of spc_edited\n",
    "spc_edited_copy = spc_edited.copy()\n",
    "\n",
    "# replace non-finite values with a default value\n",
    "spc_edited_copy['nts_ind_id'].fillna(-1, inplace=True)\n",
    "# convert the nts_ind_id column to int for merging\n",
    "spc_edited_copy['nts_ind_id'] = spc_edited_copy['nts_ind_id'].astype(int)\n",
    "\n",
    "# merge the copy with nts_trips using IndividualID\n",
    "spc_edited_copy = spc_edited_copy.merge(nts_trips,\n",
    "                                        left_on='nts_ind_id', right_on='IndividualID',\n",
    "                                        how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spc_edited_copy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the file as a parquet file\n",
    "spc_edited_copy.to_parquet(get_interim_path('spc_with_nts_trips.parquet'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acbm-7iKwKWLy-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
